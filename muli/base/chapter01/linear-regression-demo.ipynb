{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import ndarray as nd\n",
    "from mxnet import autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "num_inputs=2 \n",
    "num_examples=1000\n",
    "true_w=[2,-3.4]\n",
    "true_b=4.2\n",
    "X=nd.random_normal(shape=(num_examples,num_inputs)) \n",
    "y=true_w[0]*X[:,0]+true_w[1]*X[:,1]+true_b\n",
    "y+=0.01*nd.random_normal(shape=y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1.1630787 0.4838046]\n",
      "<NDArray 2 @cpu(0)> \n",
      "[4.879625]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(X[0],y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "batch_size=10 \n",
    "def data_iter():\n",
    "    # 产生一个随机索引 \n",
    "    idx=list(range(num_examples))\n",
    "    random.shuffle(idx)\n",
    "    for i in range(0,num_examples,batch_size):\n",
    "        j=nd.array(idx[i:min(i+batch_size,num_examples)]) \n",
    "        yield nd.take(X,j),nd.take(y,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面代码读取第一个随机数据块 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "n=0 \n",
    "for data,label in data_iter():\n",
    "    n=n+1\n",
    "#     print(data,label)\n",
    "#     break \n",
    "print(n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=nd.random_normal(shape=(num_inputs,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.4642214]\n",
       " [-1.3058136]]\n",
       "<NDArray 2x1 @cpu(0)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=nd.zeros((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=[w,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " [[ 1.4642214]\n",
       "  [-1.3058136]]\n",
       " <NDArray 2x1 @cpu(0)>,\n",
       " \n",
       " [0.]\n",
       " <NDArray 1 @cpu(0)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型\n",
    "\n",
    "线性模型，就是将输入和模型做乘法再加上偏移："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    return nd.dot(X,w)+b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数 \n",
    "我们使用常见的平方差误差来衡量目标和真实目标之间的差距 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(yhat,y):\n",
    "    # 注意我们这里把y变成yhat的形状来避免自动广播 \n",
    "    return (yhat-y.reshape(yhat.shape))**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.61562586  1.1182038 ]\n",
       " [ 1.8987794  -1.1283919 ]\n",
       " [ 0.72018015  0.9385755 ]\n",
       " [-0.6079571   0.05669585]\n",
       " [-0.25059152 -0.06146848]\n",
       " [-1.8885834   0.6752996 ]\n",
       " [-0.04796145 -0.912849  ]\n",
       " [-0.4337191   1.3150975 ]\n",
       " [ 0.14341475  0.42924684]\n",
       " [ 1.8307649  -1.1468065 ]]\n",
       "<NDArray 10x2 @cpu(0)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-2.3615782 ]\n",
       " [ 4.2537026 ]\n",
       " [-0.17110145]\n",
       " [-0.964218  ]\n",
       " [-0.28665507]\n",
       " [-3.6471195 ]\n",
       " [ 1.1217844 ]\n",
       " [-2.3523328 ]\n",
       " [-0.3505254 ]\n",
       " [ 4.1781607 ]]\n",
       "<NDArray 10x1 @cpu(0)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 优化 \n",
    "虽然线性回归有显式解，但绝大部分模型并没有，所以我们这里通过随机梯度下降来求解。\n",
    "每一步，我们将模型参数沿着梯度的反方向走特定距离，这个距离一般叫做学习率。\n",
    "（我们之后一直使用这个函数，我们将其保存在utils.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(params,lr):\n",
    "    for param in params:\n",
    "        param[:]=param -lr *param.grad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练 \n",
    "现在我们可以开始训练了。训练通常需要迭代数据数次，一次迭代里，我们每次随机读取固定数个\n",
    "数据点，计算梯度并更新模型参数 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 , average loss : 18.376279 \n",
      "Epoch 1 , average loss : 12.330371 \n",
      "Epoch 2 , average loss : 8.272645 \n",
      "Epoch 3 , average loss : 5.551243 \n",
      "Epoch 4 , average loss : 3.725228 \n",
      "Epoch 5 , average loss : 2.500241 \n",
      "Epoch 6 , average loss : 1.677955 \n",
      "Epoch 7 , average loss : 1.126274 \n",
      "Epoch 8 , average loss : 0.755946 \n",
      "Epoch 9 , average loss : 0.507494 \n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "learning_rate=0.0001 \n",
    "for e in range(epochs):\n",
    "    total_loss=0 \n",
    "    for data,label in data_iter():\n",
    "        with autograd.record():\n",
    "            output=net(data) \n",
    "            loss=square_loss(output,label) \n",
    "        loss.backward()\n",
    "        SGD(params,learning_rate) \n",
    "        total_loss+=nd.sum(loss).asscalar()\n",
    "    print(\"Epoch %d , average loss : %f \" % (e,total_loss/num_examples)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, -3.4],\n",
       " \n",
       " [[ 1.9509478]\n",
       "  [-3.1094334]]\n",
       " <NDArray 2x1 @cpu(0)>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_w,w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.2,\n",
       " \n",
       " [3.6283202]\n",
       " <NDArray 1 @cpu(0)>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_b , b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
