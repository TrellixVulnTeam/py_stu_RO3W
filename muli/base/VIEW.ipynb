{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61, loss 0.27803, train_acc 0.8276, valid_acc 0.8912, Time 00:04:02,lr 0.1\n",
      "epoch 62, loss 0.27250, train_acc 0.8301, valid_acc 0.8830, Time 00:03:57,lr 0.1\n",
      "epoch 63, loss 0.26905, train_acc 0.8325, valid_acc 0.8695, Time 00:03:55,lr 0.1\n",
      "epoch 64, loss 0.27162, train_acc 0.8318, valid_acc 0.8721, Time 00:04:03,lr 0.1\n",
      "epoch 65, loss 0.27209, train_acc 0.8306, valid_acc 0.8861, Time 00:03:56,lr 0.1\n",
      "epoch 66, loss 0.26868, train_acc 0.8317, valid_acc 0.8914, Time 00:03:56,lr 0.1\n",
      "epoch 67, loss 0.26467, train_acc 0.8349, valid_acc 0.8408, Time 00:04:03,lr 0.1\n",
      "epoch 68, loss 0.27097, train_acc 0.8321, valid_acc 0.8705, Time 00:03:59,lr 0.1\n",
      "epoch 69, loss 0.27383, train_acc 0.8290, valid_acc 0.8793, Time 00:03:56,lr 0.1\n",
      "epoch 70, loss 0.26958, train_acc 0.8323, valid_acc 0.9018, Time 00:03:55,lr 0.1\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#  !tail -f /home/dske/lx/workspace/CIFAR10_mxnet/CIFAR10_train.log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup: ignoring input\r\n",
      "train_valid_test dir has been created and if you want to recreate them\r\n",
      "set force_recreate=True(normally you needn't to do it.)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"CIFAR10_train-Copy1.py\", line 327, in <module>\r\n",
      "    lr_period, lr_decay, weight_decay, ctx, w_key, log_file, False, loss_f)\r\n",
      "  File \"CIFAR10_train-Copy1.py\", line 236, in train\r\n",
      "    for data, label in train_data:\r\n",
      "  File \"/home/dske/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/dataloader.py\", line 635, in same_process_iter\r\n",
      "    ret = self._batchify_fn([self._dataset[idx] for idx in batch])\r\n",
      "  File \"/home/dske/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/dataloader.py\", line 635, in <listcomp>\r\n",
      "    ret = self._batchify_fn([self._dataset[idx] for idx in batch])\r\n",
      "  File \"/home/dske/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/vision/datasets.py\", line 326, in __getitem__\r\n",
      "    return self._transform(img, label)\r\n",
      "  File \"CIFAR10_train-Copy1.py\", line 151, in transform_train_DA2\r\n",
      "    auglist = [image.RandomSizedCropAug(size=(32, 32), min_area=0.49, ratio=(0.5, 2))]\r\n",
      "TypeError: __init__() missing 1 required positional argument: 'area'\r\n",
      "nohup: ignoring input\r\n",
      "train_valid_test dir has been created and if you want to recreate them\r\n",
      "set force_recreate=True(normally you needn't to do it.)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"CIFAR10_train-Copy1.py\", line 327, in <module>\r\n",
      "    lr_period, lr_decay, weight_decay, ctx, w_key, log_file, False, loss_f)\r\n",
      "  File \"CIFAR10_train-Copy1.py\", line 236, in train\r\n",
      "    for data, label in train_data:\r\n",
      "  File \"/home/dske/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/dataloader.py\", line 635, in same_process_iter\r\n",
      "    ret = self._batchify_fn([self._dataset[idx] for idx in batch])\r\n",
      "  File \"/home/dske/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/dataloader.py\", line 635, in <listcomp>\r\n",
      "    ret = self._batchify_fn([self._dataset[idx] for idx in batch])\r\n",
      "  File \"/home/dske/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/vision/datasets.py\", line 326, in __getitem__\r\n",
      "    return self._transform(img, label)\r\n",
      "  File \"CIFAR10_train-Copy1.py\", line 151, in transform_train_DA2\r\n",
      "    auglist = [image.RandomSizedCropAug(size=(32, 32), min_area=0.49, ratio=(0.5, 2))]\r\n",
      "TypeError: __init__() missing 1 required positional argument: 'area'\r\n",
      "nohup: ignoring input\r\n",
      "[13:00:23] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n",
      "train_valid_test dir has been created and if you want to recreate them\r\n",
      "set force_recreate=True(normally you needn't to do it.)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"CIFAR10_train-Copy1.py\", line 327, in <module>\r\n",
      "    lr_period, lr_decay, weight_decay, ctx, w_key, log_file, False, loss_f)\r\n",
      "  File \"CIFAR10_train-Copy1.py\", line 244, in train\r\n",
      "    _loss = nd.mean(loss).asscalar()\r\n",
      "  File \"/home/dske/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\", line 2585, in asscalar\r\n",
      "    return self.asnumpy()[0]\r\n",
      "  File \"/home/dske/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\", line 2566, in asnumpy\r\n",
      "    ctypes.c_size_t(data.size)))\r\n",
      "  File \"/home/dske/anaconda3/lib/python3.7/site-packages/mxnet/base.py\", line 246, in check_call\r\n",
      "    raise get_last_ffi_error()\r\n",
      "mxnet.base.MXNetError: Traceback (most recent call last):\r\n",
      "  File \"src/storage/./pooled_storage_manager.h\", line 161\r\n",
      "MXNetError: cudaMalloc retry failed: out of memory\r\n",
      "nohup: ignoring input\r\n",
      "[14:08:00] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n",
      "train_valid_test dir has been created and if you want to recreate them\r\n",
      "set force_recreate=True(normally you needn't to do it.)\r\n",
      "epoch 0, loss 1.92642, train_acc 0.2882, valid_acc 0.4203, Time 00:03:50,lr 0.1\r\n",
      "epoch 1, loss 1.40610, train_acc 0.4960, valid_acc 0.5713, Time 00:03:56,lr 0.1\r\n",
      "epoch 2, loss 1.11664, train_acc 0.6029, valid_acc 0.6529, Time 00:04:00,lr 0.1\r\n",
      "epoch 3, loss 0.96248, train_acc 0.6615, valid_acc 0.7260, Time 00:03:50,lr 0.1\r\n",
      "epoch 4, loss 0.85208, train_acc 0.7011, valid_acc 0.7355, Time 00:03:53,lr 0.1\r\n",
      "epoch 5, loss 0.78523, train_acc 0.7242, valid_acc 0.7523, Time 00:03:54,lr 0.1\r\n",
      "epoch 6, loss 0.72897, train_acc 0.7461, valid_acc 0.7639, Time 00:04:05,lr 0.1\r\n",
      "epoch 7, loss 0.68286, train_acc 0.7610, valid_acc 0.7832, Time 00:03:55,lr 0.1\r\n",
      "epoch 8, loss 0.65065, train_acc 0.7750, valid_acc 0.7777, Time 00:03:50,lr 0.1\r\n",
      "epoch 9, loss 0.61889, train_acc 0.7852, valid_acc 0.8027, Time 00:03:52,lr 0.1\r\n",
      "epoch 10, loss 0.59622, train_acc 0.7943, valid_acc 0.8174, Time 00:03:50,lr 0.1\r\n",
      "epoch 11, loss 0.56475, train_acc 0.8062, valid_acc 0.8301, Time 00:03:59,lr 0.1\r\n",
      "epoch 12, loss 0.55701, train_acc 0.8078, valid_acc 0.8332, Time 00:03:53,lr 0.1\r\n",
      "epoch 13, loss 0.54191, train_acc 0.8127, valid_acc 0.8455, Time 00:03:54,lr 0.1\r\n",
      "epoch 14, loss 0.52330, train_acc 0.8175, valid_acc 0.8461, Time 00:03:53,lr 0.1\r\n",
      "epoch 15, loss 0.50296, train_acc 0.8261, valid_acc 0.8381, Time 00:03:54,lr 0.1\r\n",
      "epoch 16, loss 0.49364, train_acc 0.8282, valid_acc 0.8740, Time 00:03:52,lr 0.1\r\n",
      "epoch 17, loss 0.47777, train_acc 0.8359, valid_acc 0.8246, Time 00:03:59,lr 0.1\r\n",
      "epoch 18, loss 0.47128, train_acc 0.8376, valid_acc 0.8475, Time 00:03:50,lr 0.1\r\n",
      "epoch 19, loss 0.46495, train_acc 0.8379, valid_acc 0.8738, Time 00:04:00,lr 0.1\r\n",
      "epoch 20, loss 0.45582, train_acc 0.8424, valid_acc 0.8441, Time 00:04:01,lr 0.1\r\n",
      "epoch 21, loss 0.43771, train_acc 0.8496, valid_acc 0.8615, Time 00:03:54,lr 0.1\r\n",
      "epoch 22, loss 0.43283, train_acc 0.8505, valid_acc 0.8654, Time 00:03:53,lr 0.1\r\n",
      "epoch 23, loss 0.43628, train_acc 0.8499, valid_acc 0.8799, Time 00:03:52,lr 0.1\r\n",
      "epoch 24, loss 0.41982, train_acc 0.8552, valid_acc 0.8758, Time 00:03:51,lr 0.1\r\n",
      "epoch 25, loss 0.41654, train_acc 0.8561, valid_acc 0.8695, Time 00:03:53,lr 0.1\r\n",
      "epoch 26, loss 0.40888, train_acc 0.8584, valid_acc 0.8904, Time 00:04:01,lr 0.1\r\n",
      "epoch 27, loss 0.40580, train_acc 0.8584, valid_acc 0.8715, Time 00:03:58,lr 0.1\r\n",
      "epoch 28, loss 0.40815, train_acc 0.8591, valid_acc 0.8805, Time 00:03:56,lr 0.1\r\n",
      "epoch 29, loss 0.40472, train_acc 0.8591, valid_acc 0.8770, Time 00:03:52,lr 0.1\r\n",
      "epoch 30, loss 0.40019, train_acc 0.8619, valid_acc 0.8572, Time 00:03:52,lr 0.1\r\n",
      "epoch 31, loss 0.39811, train_acc 0.8620, valid_acc 0.8707, Time 00:03:55,lr 0.1\r\n",
      "epoch 32, loss 0.38899, train_acc 0.8633, valid_acc 0.8889, Time 00:03:54,lr 0.1\r\n",
      "epoch 33, loss 0.38814, train_acc 0.8647, valid_acc 0.8723, Time 00:03:53,lr 0.1\r\n",
      "epoch 34, loss 0.38176, train_acc 0.8677, valid_acc 0.8910, Time 00:03:55,lr 0.1\r\n",
      "epoch 35, loss 0.37746, train_acc 0.8682, valid_acc 0.8807, Time 00:03:53,lr 0.1\r\n",
      "epoch 36, loss 0.37913, train_acc 0.8698, valid_acc 0.8867, Time 00:03:50,lr 0.1\r\n",
      "epoch 37, loss 0.37666, train_acc 0.8693, valid_acc 0.8703, Time 00:04:00,lr 0.1\r\n",
      "epoch 38, loss 0.37591, train_acc 0.8716, valid_acc 0.8947, Time 00:03:59,lr 0.1\r\n",
      "epoch 39, loss 0.37150, train_acc 0.8716, valid_acc 0.9002, Time 00:03:54,lr 0.1\r\n",
      "epoch 40, loss 0.37200, train_acc 0.8709, valid_acc 0.8889, Time 00:03:52,lr 0.1\r\n",
      "epoch 41, loss 0.37667, train_acc 0.8692, valid_acc 0.8797, Time 00:03:54,lr 0.1\r\n",
      "epoch 42, loss 0.36217, train_acc 0.8741, valid_acc 0.8912, Time 00:03:57,lr 0.1\r\n",
      "epoch 43, loss 0.37063, train_acc 0.8719, valid_acc 0.8955, Time 00:03:52,lr 0.1\r\n",
      "epoch 44, loss 0.36382, train_acc 0.8743, valid_acc 0.8852, Time 00:04:03,lr 0.1\r\n",
      "epoch 45, loss 0.36165, train_acc 0.8760, valid_acc 0.8760, Time 00:03:53,lr 0.1\r\n",
      "epoch 46, loss 0.35618, train_acc 0.8770, valid_acc 0.9008, Time 00:03:55,lr 0.1\r\n",
      "epoch 47, loss 0.35714, train_acc 0.8764, valid_acc 0.8805, Time 00:03:54,lr 0.1\r\n",
      "epoch 48, loss 0.34660, train_acc 0.8801, valid_acc 0.8791, Time 00:03:52,lr 0.1\r\n",
      "epoch 49, loss 0.34709, train_acc 0.8804, valid_acc 0.8922, Time 00:03:52,lr 0.1\r\n",
      "epoch 50, loss 0.34949, train_acc 0.8791, valid_acc 0.8979, Time 00:03:55,lr 0.1\r\n",
      "epoch 51, loss 0.35218, train_acc 0.8775, valid_acc 0.8938, Time 00:03:53,lr 0.1\r\n",
      "epoch 52, loss 0.35403, train_acc 0.8777, valid_acc 0.8898, Time 00:03:54,lr 0.1\r\n",
      "epoch 53, loss 0.34342, train_acc 0.8796, valid_acc 0.9006, Time 00:03:54,lr 0.1\r\n",
      "epoch 54, loss 0.34722, train_acc 0.8793, valid_acc 0.8900, Time 00:03:59,lr 0.1\r\n",
      "epoch 55, loss 0.34418, train_acc 0.8807, valid_acc 0.8951, Time 00:03:58,lr 0.1\r\n",
      "epoch 56, loss 0.34304, train_acc 0.8820, valid_acc 0.8812, Time 00:03:55,lr 0.1\r\n",
      "epoch 57, loss 0.33872, train_acc 0.8832, valid_acc 0.9004, Time 00:03:59,lr 0.1\r\n",
      "epoch 58, loss 0.34444, train_acc 0.8813, valid_acc 0.9000, Time 00:03:56,lr 0.1\r\n",
      "epoch 59, loss 0.34129, train_acc 0.8832, valid_acc 0.9092, Time 00:03:53,lr 0.1\r\n",
      "epoch 60, loss 0.33971, train_acc 0.8834, valid_acc 0.8855, Time 00:03:55,lr 0.1\r\n",
      "epoch 61, loss 0.34121, train_acc 0.8813, valid_acc 0.9014, Time 00:03:52,lr 0.1\r\n",
      "epoch 62, loss 0.33611, train_acc 0.8838, valid_acc 0.8885, Time 00:04:00,lr 0.1\r\n",
      "epoch 63, loss 0.33475, train_acc 0.8845, valid_acc 0.8902, Time 00:03:55,lr 0.1\r\n",
      "epoch 64, loss 0.33534, train_acc 0.8849, valid_acc 0.9051, Time 00:03:53,lr 0.1\r\n",
      "epoch 65, loss 0.33167, train_acc 0.8861, valid_acc 0.9125, Time 00:03:54,lr 0.1\r\n",
      "epoch 66, loss 0.32553, train_acc 0.8875, valid_acc 0.9008, Time 00:03:54,lr 0.1\r\n",
      "epoch 67, loss 0.32573, train_acc 0.8868, valid_acc 0.8777, Time 00:03:57,lr 0.1\r\n",
      "epoch 68, loss 0.33493, train_acc 0.8841, valid_acc 0.8967, Time 00:03:57,lr 0.1\r\n",
      "epoch 69, loss 0.32796, train_acc 0.8873, valid_acc 0.8938, Time 00:03:57,lr 0.1\r\n",
      "epoch 70, loss 0.32786, train_acc 0.8873, valid_acc 0.9107, Time 00:03:54,lr 0.1\r\n",
      "epoch 71, loss 0.32362, train_acc 0.8883, valid_acc 0.8943, Time 00:03:58,lr 0.1\r\n",
      "epoch 72, loss 0.32383, train_acc 0.8873, valid_acc 0.9059, Time 00:03:57,lr 0.1\r\n",
      "epoch 73, loss 0.32303, train_acc 0.8895, valid_acc 0.8941, Time 00:03:55,lr 0.1\r\n",
      "epoch 74, loss 0.31822, train_acc 0.8897, valid_acc 0.9018, Time 00:04:04,lr 0.1\r\n",
      "epoch 75, loss 0.31699, train_acc 0.8903, valid_acc 0.8727, Time 00:03:54,lr 0.1\r\n",
      "epoch 76, loss 0.32044, train_acc 0.8903, valid_acc 0.9014, Time 00:03:53,lr 0.1\r\n",
      "epoch 77, loss 0.31744, train_acc 0.8897, valid_acc 0.9018, Time 00:03:57,lr 0.1\r\n",
      "epoch 78, loss 0.31383, train_acc 0.8899, valid_acc 0.9043, Time 00:03:54,lr 0.1\r\n",
      "epoch 79, loss 0.31462, train_acc 0.8911, valid_acc 0.8949, Time 00:04:07,lr 0.1\r\n",
      "epoch 80, loss 0.31949, train_acc 0.8886, valid_acc 0.8914, Time 00:05:07,lr 0.1\r\n",
      "epoch 81, loss 0.31049, train_acc 0.8900, valid_acc 0.8822, Time 00:04:02,lr 0.1\r\n",
      "epoch 82, loss 0.31150, train_acc 0.8914, valid_acc 0.8943, Time 00:05:50,lr 0.1\r\n",
      "epoch 83, loss 0.31400, train_acc 0.8915, valid_acc 0.9051, Time 00:05:50,lr 0.1\r\n",
      "nohup: ignoring input\r\n",
      "[16:04:39] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n",
      "train_valid_test dir has been created and if you want to recreate them\r\n",
      "set force_recreate=True(normally you needn't to do it.)\r\n",
      "epoch 0, loss 1.88871, train_acc 0.3042, valid_acc 0.3887, Time 00:03:48,lr 0.1\r\n",
      "epoch 1, loss 1.37770, train_acc 0.5056, valid_acc 0.5707, Time 00:03:56,lr 0.1\r\n",
      "epoch 2, loss 1.09986, train_acc 0.6099, valid_acc 0.6406, Time 00:03:51,lr 0.1\r\n",
      "epoch 3, loss 0.94671, train_acc 0.6671, valid_acc 0.7168, Time 00:03:54,lr 0.1\r\n",
      "epoch 4, loss 0.85196, train_acc 0.7034, valid_acc 0.7412, Time 00:03:54,lr 0.1\r\n",
      "epoch 5, loss 0.77945, train_acc 0.7282, valid_acc 0.7541, Time 00:03:56,lr 0.1\r\n",
      "epoch 6, loss 0.72623, train_acc 0.7468, valid_acc 0.7514, Time 00:03:53,lr 0.1\r\n",
      "epoch 7, loss 0.68523, train_acc 0.7623, valid_acc 0.7779, Time 00:03:49,lr 0.1\r\n",
      "epoch 8, loss 0.64727, train_acc 0.7758, valid_acc 0.7838, Time 00:04:02,lr 0.1\r\n",
      "epoch 9, loss 0.61839, train_acc 0.7852, valid_acc 0.8074, Time 00:03:58,lr 0.1\r\n",
      "epoch 10, loss 0.59084, train_acc 0.7941, valid_acc 0.8156, Time 00:03:51,lr 0.1\r\n",
      "epoch 11, loss 0.56983, train_acc 0.8031, valid_acc 0.8287, Time 00:03:49,lr 0.1\r\n",
      "epoch 12, loss 0.55231, train_acc 0.8089, valid_acc 0.8500, Time 00:03:52,lr 0.1\r\n",
      "epoch 13, loss 0.53022, train_acc 0.8196, valid_acc 0.8303, Time 00:03:54,lr 0.1\r\n",
      "epoch 14, loss 0.51774, train_acc 0.8205, valid_acc 0.8529, Time 00:03:56,lr 0.1\r\n",
      "epoch 15, loss 0.49910, train_acc 0.8268, valid_acc 0.8529, Time 00:03:57,lr 0.1\r\n",
      "epoch 16, loss 0.48937, train_acc 0.8291, valid_acc 0.8670, Time 00:03:54,lr 0.1\r\n",
      "epoch 17, loss 0.48196, train_acc 0.8345, valid_acc 0.8641, Time 00:03:52,lr 0.1\r\n",
      "epoch 18, loss 0.46991, train_acc 0.8370, valid_acc 0.8760, Time 00:03:55,lr 0.1\r\n",
      "epoch 19, loss 0.45924, train_acc 0.8427, valid_acc 0.8695, Time 00:03:54,lr 0.1\r\n",
      "epoch 20, loss 0.45005, train_acc 0.8456, valid_acc 0.8711, Time 00:03:52,lr 0.1\r\n",
      "epoch 21, loss 0.43722, train_acc 0.8497, valid_acc 0.8586, Time 00:03:50,lr 0.1\r\n",
      "epoch 22, loss 0.43563, train_acc 0.8496, valid_acc 0.8574, Time 00:03:49,lr 0.1\r\n",
      "epoch 23, loss 0.42641, train_acc 0.8525, valid_acc 0.8721, Time 00:03:54,lr 0.1\r\n",
      "epoch 24, loss 0.42399, train_acc 0.8522, valid_acc 0.8422, Time 00:03:55,lr 0.1\r\n",
      "epoch 25, loss 0.42283, train_acc 0.8515, valid_acc 0.8688, Time 00:03:52,lr 0.1\r\n",
      "epoch 26, loss 0.40801, train_acc 0.8585, valid_acc 0.8785, Time 00:03:51,lr 0.1\r\n",
      "epoch 27, loss 0.40830, train_acc 0.8597, valid_acc 0.8820, Time 00:03:54,lr 0.1\r\n",
      "epoch 28, loss 0.39926, train_acc 0.8616, valid_acc 0.8865, Time 00:03:53,lr 0.1\r\n",
      "epoch 29, loss 0.39608, train_acc 0.8635, valid_acc 0.8631, Time 00:03:50,lr 0.1\r\n",
      "epoch 30, loss 0.39247, train_acc 0.8637, valid_acc 0.8758, Time 00:03:53,lr 0.1\r\n",
      "epoch 31, loss 0.39809, train_acc 0.8611, valid_acc 0.8682, Time 00:03:49,lr 0.1\r\n",
      "epoch 32, loss 0.39072, train_acc 0.8641, valid_acc 0.8633, Time 00:04:00,lr 0.1\r\n",
      "epoch 33, loss 0.38741, train_acc 0.8642, valid_acc 0.8895, Time 00:04:06,lr 0.1\r\n",
      "epoch 34, loss 0.37576, train_acc 0.8696, valid_acc 0.8771, Time 00:04:06,lr 0.1\r\n",
      "epoch 35, loss 0.37730, train_acc 0.8684, valid_acc 0.8725, Time 00:03:56,lr 0.1\r\n",
      "epoch 36, loss 0.37546, train_acc 0.8691, valid_acc 0.9076, Time 00:03:57,lr 0.1\r\n",
      "epoch 37, loss 0.37262, train_acc 0.8715, valid_acc 0.8799, Time 00:03:53,lr 0.1\r\n",
      "epoch 38, loss 0.37320, train_acc 0.8711, valid_acc 0.8902, Time 00:03:52,lr 0.1\r\n",
      "epoch 39, loss 0.36428, train_acc 0.8752, valid_acc 0.8900, Time 00:03:53,lr 0.1\r\n",
      "epoch 40, loss 0.37926, train_acc 0.8671, valid_acc 0.8979, Time 00:03:55,lr 0.1\r\n",
      "epoch 41, loss 0.37367, train_acc 0.8699, valid_acc 0.8768, Time 00:03:53,lr 0.1\r\n",
      "epoch 42, loss 0.35873, train_acc 0.8748, valid_acc 0.8904, Time 00:03:53,lr 0.1\r\n",
      "epoch 43, loss 0.36142, train_acc 0.8752, valid_acc 0.8963, Time 00:03:56,lr 0.1\r\n",
      "epoch 44, loss 0.36314, train_acc 0.8742, valid_acc 0.8904, Time 00:03:56,lr 0.1\r\n",
      "epoch 45, loss 0.36416, train_acc 0.8736, valid_acc 0.8803, Time 00:03:55,lr 0.1\r\n",
      "epoch 46, loss 0.35872, train_acc 0.8771, valid_acc 0.8840, Time 00:03:55,lr 0.1\r\n",
      "epoch 47, loss 0.35266, train_acc 0.8774, valid_acc 0.9086, Time 00:03:50,lr 0.1\r\n",
      "epoch 48, loss 0.35272, train_acc 0.8764, valid_acc 0.8941, Time 00:03:49,lr 0.1\r\n",
      "epoch 49, loss 0.34961, train_acc 0.8794, valid_acc 0.8961, Time 00:03:50,lr 0.1\r\n",
      "epoch 50, loss 0.34588, train_acc 0.8794, valid_acc 0.8910, Time 00:03:51,lr 0.1\r\n",
      "epoch 51, loss 0.34296, train_acc 0.8804, valid_acc 0.8844, Time 00:03:56,lr 0.1\r\n",
      "epoch 52, loss 0.34639, train_acc 0.8801, valid_acc 0.8908, Time 00:03:55,lr 0.1\r\n",
      "epoch 53, loss 0.34669, train_acc 0.8801, valid_acc 0.8934, Time 00:03:56,lr 0.1\r\n",
      "epoch 54, loss 0.34146, train_acc 0.8815, valid_acc 0.8900, Time 00:03:58,lr 0.1\r\n",
      "epoch 55, loss 0.34483, train_acc 0.8809, valid_acc 0.8721, Time 00:03:53,lr 0.1\r\n",
      "epoch 56, loss 0.35161, train_acc 0.8774, valid_acc 0.8770, Time 00:03:54,lr 0.1\r\n",
      "epoch 57, loss 0.33726, train_acc 0.8816, valid_acc 0.8746, Time 00:03:51,lr 0.1\r\n",
      "epoch 58, loss 0.33907, train_acc 0.8815, valid_acc 0.8807, Time 00:03:53,lr 0.1\r\n",
      "epoch 59, loss 0.33581, train_acc 0.8831, valid_acc 0.8977, Time 00:03:50,lr 0.1\r\n",
      "epoch 60, loss 0.33014, train_acc 0.8863, valid_acc 0.8904, Time 00:03:59,lr 0.1\r\n",
      "epoch 61, loss 0.34053, train_acc 0.8828, valid_acc 0.8930, Time 00:03:56,lr 0.1\r\n",
      "epoch 62, loss 0.32913, train_acc 0.8851, valid_acc 0.8744, Time 00:03:50,lr 0.1\r\n",
      "epoch 63, loss 0.33367, train_acc 0.8837, valid_acc 0.8914, Time 00:03:56,lr 0.1\r\n",
      "epoch 64, loss 0.33667, train_acc 0.8838, valid_acc 0.8977, Time 00:03:58,lr 0.1\r\n",
      "epoch 65, loss 0.32790, train_acc 0.8869, valid_acc 0.8898, Time 00:03:50,lr 0.1\r\n",
      "epoch 66, loss 0.32798, train_acc 0.8861, valid_acc 0.9080, Time 00:03:56,lr 0.1\r\n",
      "epoch 67, loss 0.33465, train_acc 0.8850, valid_acc 0.8982, Time 00:03:53,lr 0.1\r\n",
      "epoch 68, loss 0.32275, train_acc 0.8883, valid_acc 0.9039, Time 00:03:55,lr 0.1\r\n",
      "epoch 69, loss 0.32833, train_acc 0.8860, valid_acc 0.8838, Time 00:03:59,lr 0.1\r\n",
      "epoch 70, loss 0.32371, train_acc 0.8884, valid_acc 0.8908, Time 00:03:50,lr 0.1\r\n",
      "epoch 71, loss 0.32508, train_acc 0.8873, valid_acc 0.9020, Time 00:04:03,lr 0.1\r\n",
      "epoch 72, loss 0.32072, train_acc 0.8874, valid_acc 0.9006, Time 00:04:00,lr 0.1\r\n",
      "epoch 73, loss 0.31508, train_acc 0.8922, valid_acc 0.8975, Time 00:03:50,lr 0.1\r\n",
      "epoch 74, loss 0.31890, train_acc 0.8890, valid_acc 0.9041, Time 00:03:53,lr 0.1\r\n",
      "epoch 75, loss 0.31900, train_acc 0.8910, valid_acc 0.9098, Time 00:03:56,lr 0.1\r\n",
      "epoch 76, loss 0.31922, train_acc 0.8885, valid_acc 0.9006, Time 00:03:53,lr 0.1\r\n",
      "epoch 77, loss 0.31188, train_acc 0.8915, valid_acc 0.9070, Time 00:03:54,lr 0.1\r\n",
      "epoch 78, loss 0.31745, train_acc 0.8900, valid_acc 0.9029, Time 00:03:53,lr 0.1\r\n",
      "epoch 79, loss 0.31106, train_acc 0.8914, valid_acc 0.8803, Time 00:03:55,lr 0.1\r\n",
      "epoch 80, loss 0.31804, train_acc 0.8913, valid_acc 0.8840, Time 00:03:57,lr 0.1\r\n",
      "epoch 81, loss 0.30392, train_acc 0.8949, valid_acc 0.8963, Time 00:03:49,lr 0.1\r\n",
      "epoch 82, loss 0.31333, train_acc 0.8920, valid_acc 0.9020, Time 00:03:52,lr 0.1\r\n",
      "epoch 83, loss 0.30863, train_acc 0.8934, valid_acc 0.8764, Time 00:04:09,lr 0.1\r\n",
      "epoch 84, loss 0.31222, train_acc 0.8909, valid_acc 0.8984, Time 00:04:14,lr 0.1\r\n",
      "epoch 85, loss 0.31108, train_acc 0.8914, valid_acc 0.8867, Time 00:03:55,lr 0.1\r\n",
      "epoch 86, loss 0.30798, train_acc 0.8935, valid_acc 0.9016, Time 00:03:54,lr 0.1\r\n",
      "epoch 87, loss 0.31000, train_acc 0.8931, valid_acc 0.9010, Time 00:03:53,lr 0.1\r\n",
      "epoch 88, loss 0.30276, train_acc 0.8938, valid_acc 0.9006, Time 00:03:52,lr 0.1\r\n",
      "epoch 89, loss 0.31283, train_acc 0.8899, valid_acc 0.8918, Time 00:03:52,lr 0.1\r\n",
      "epoch 90, loss 0.29681, train_acc 0.8974, valid_acc 0.8994, Time 00:03:53,lr 0.1\r\n",
      "epoch 91, loss 0.30632, train_acc 0.8927, valid_acc 0.8918, Time 00:03:57,lr 0.1\r\n",
      "epoch 92, loss 0.29822, train_acc 0.8972, valid_acc 0.9043, Time 00:04:00,lr 0.1\r\n",
      "epoch 93, loss 0.29912, train_acc 0.8958, valid_acc 0.9049, Time 00:04:03,lr 0.1\r\n",
      "epoch 94, loss 0.30594, train_acc 0.8957, valid_acc 0.9123, Time 00:03:56,lr 0.1\r\n",
      "epoch 95, loss 0.30122, train_acc 0.8943, valid_acc 0.8961, Time 00:03:50,lr 0.1\r\n",
      "epoch 96, loss 0.30071, train_acc 0.8949, valid_acc 0.9027, Time 00:03:54,lr 0.1\r\n",
      "epoch 97, loss 0.29809, train_acc 0.8976, valid_acc 0.8965, Time 00:03:55,lr 0.1\r\n",
      "epoch 98, loss 0.29470, train_acc 0.8988, valid_acc 0.8900, Time 00:04:02,lr 0.1\r\n",
      "epoch 99, loss 0.30134, train_acc 0.8946, valid_acc 0.9104, Time 00:03:59,lr 0.1\r\n",
      "epoch 100, loss 0.29482, train_acc 0.8978, valid_acc 0.9117, Time 00:03:55,lr 0.1\r\n",
      "epoch 101, loss 0.29530, train_acc 0.8973, valid_acc 0.9139, Time 00:03:52,lr 0.1\r\n",
      "epoch 102, loss 0.29399, train_acc 0.8972, valid_acc 0.9186, Time 00:03:57,lr 0.1\r\n",
      "epoch 103, loss 0.28691, train_acc 0.9001, valid_acc 0.9014, Time 00:03:55,lr 0.1\r\n",
      "epoch 104, loss 0.28846, train_acc 0.9007, valid_acc 0.9113, Time 00:03:54,lr 0.1\r\n",
      "epoch 105, loss 0.29007, train_acc 0.8990, valid_acc 0.9102, Time 00:03:53,lr 0.1\r\n",
      "epoch 106, loss 0.29328, train_acc 0.8984, valid_acc 0.8969, Time 00:03:54,lr 0.1\r\n",
      "epoch 107, loss 0.28855, train_acc 0.9006, valid_acc 0.8965, Time 00:04:03,lr 0.1\r\n",
      "epoch 108, loss 0.29665, train_acc 0.8956, valid_acc 0.8988, Time 00:03:54,lr 0.1\r\n",
      "epoch 109, loss 0.28942, train_acc 0.9012, valid_acc 0.9191, Time 00:04:05,lr 0.1\r\n",
      "epoch 110, loss 0.28489, train_acc 0.9008, valid_acc 0.9158, Time 00:03:57,lr 0.1\r\n",
      "epoch 111, loss 0.28673, train_acc 0.9011, valid_acc 0.9086, Time 00:03:54,lr 0.1\r\n",
      "epoch 112, loss 0.29017, train_acc 0.9002, valid_acc 0.9070, Time 00:03:52,lr 0.1\r\n",
      "epoch 113, loss 0.28547, train_acc 0.9012, valid_acc 0.9105, Time 00:03:48,lr 0.1\r\n",
      "epoch 114, loss 0.28654, train_acc 0.9011, valid_acc 0.9029, Time 00:03:53,lr 0.1\r\n",
      "epoch 115, loss 0.28688, train_acc 0.9014, valid_acc 0.8850, Time 00:04:00,lr 0.1\r\n",
      "epoch 116, loss 0.29037, train_acc 0.8993, valid_acc 0.9021, Time 00:03:53,lr 0.1\r\n",
      "epoch 117, loss 0.28881, train_acc 0.8997, valid_acc 0.8961, Time 00:03:56,lr 0.1\r\n",
      "epoch 118, loss 0.28286, train_acc 0.9017, valid_acc 0.9104, Time 00:03:50,lr 0.1\r\n",
      "epoch 119, loss 0.27881, train_acc 0.9023, valid_acc 0.9025, Time 00:04:07,lr 0.1\r\n",
      "epoch 120, loss 0.27733, train_acc 0.9029, valid_acc 0.9129, Time 00:03:56,lr 0.1\r\n",
      "epoch 121, loss 0.28661, train_acc 0.8999, valid_acc 0.8984, Time 00:03:52,lr 0.1\r\n",
      "epoch 122, loss 0.27797, train_acc 0.9028, valid_acc 0.9123, Time 00:03:54,lr 0.1\r\n",
      "epoch 123, loss 0.28261, train_acc 0.9018, valid_acc 0.9057, Time 00:04:04,lr 0.1\r\n",
      "epoch 124, loss 0.28208, train_acc 0.9002, valid_acc 0.9035, Time 00:03:54,lr 0.1\r\n",
      "epoch 125, loss 0.28047, train_acc 0.9027, valid_acc 0.9049, Time 00:03:48,lr 0.1\r\n",
      "epoch 126, loss 0.27801, train_acc 0.9046, valid_acc 0.9096, Time 00:03:52,lr 0.1\r\n",
      "epoch 127, loss 0.28193, train_acc 0.9017, valid_acc 0.9033, Time 00:03:54,lr 0.1\r\n",
      "epoch 128, loss 0.27744, train_acc 0.9035, valid_acc 0.8836, Time 00:03:49,lr 0.1\r\n",
      "epoch 129, loss 0.28122, train_acc 0.9044, valid_acc 0.8883, Time 00:03:52,lr 0.1\r\n",
      "epoch 130, loss 0.27390, train_acc 0.9057, valid_acc 0.8840, Time 00:03:54,lr 0.1\r\n",
      "epoch 131, loss 0.26990, train_acc 0.9051, valid_acc 0.9021, Time 00:03:52,lr 0.1\r\n",
      "epoch 132, loss 0.27571, train_acc 0.9046, valid_acc 0.8920, Time 00:03:56,lr 0.1\r\n",
      "epoch 133, loss 0.27517, train_acc 0.9041, valid_acc 0.9090, Time 00:04:00,lr 0.1\r\n",
      "epoch 134, loss 0.27205, train_acc 0.9056, valid_acc 0.9037, Time 00:03:51,lr 0.1\r\n",
      "epoch 135, loss 0.27714, train_acc 0.9025, valid_acc 0.9184, Time 00:03:54,lr 0.1\r\n",
      "epoch 136, loss 0.27448, train_acc 0.9036, valid_acc 0.8910, Time 00:03:58,lr 0.1\r\n",
      "epoch 137, loss 0.27223, train_acc 0.9058, valid_acc 0.9150, Time 00:03:53,lr 0.1\r\n",
      "epoch 138, loss 0.27554, train_acc 0.9039, valid_acc 0.9104, Time 00:03:52,lr 0.1\r\n",
      "epoch 139, loss 0.28024, train_acc 0.9031, valid_acc 0.9016, Time 00:03:55,lr 0.1\r\n",
      "epoch 140, loss 0.26844, train_acc 0.9071, valid_acc 0.8986, Time 00:03:55,lr 0.1\r\n",
      "epoch 141, loss 0.27228, train_acc 0.9050, valid_acc 0.9076, Time 00:03:53,lr 0.1\r\n",
      "epoch 142, loss 0.27065, train_acc 0.9071, valid_acc 0.8965, Time 00:03:54,lr 0.1\r\n",
      "epoch 143, loss 0.27349, train_acc 0.9056, valid_acc 0.9104, Time 00:03:51,lr 0.1\r\n",
      "epoch 144, loss 0.27047, train_acc 0.9056, valid_acc 0.8967, Time 00:04:00,lr 0.1\r\n",
      "epoch 145, loss 0.27051, train_acc 0.9047, valid_acc 0.9023, Time 00:03:59,lr 0.1\r\n",
      "epoch 146, loss 0.27363, train_acc 0.9054, valid_acc 0.9045, Time 00:04:00,lr 0.1\r\n",
      "epoch 147, loss 0.26720, train_acc 0.9071, valid_acc 0.9076, Time 00:03:51,lr 0.1\r\n",
      "epoch 148, loss 0.26811, train_acc 0.9081, valid_acc 0.9143, Time 00:03:59,lr 0.1\r\n",
      "epoch 149, loss 0.27721, train_acc 0.9040, valid_acc 0.9141, Time 00:04:00,lr 0.1\r\n",
      "epoch 150, loss 0.18301, train_acc 0.9376, valid_acc 0.9473, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 151, loss 0.12856, train_acc 0.9570, valid_acc 0.9512, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 152, loss 0.11942, train_acc 0.9606, valid_acc 0.9521, Time 00:03:54,lr 0.010000000000000002\r\n",
      "epoch 153, loss 0.10387, train_acc 0.9660, valid_acc 0.9518, Time 00:03:56,lr 0.010000000000000002\r\n",
      "epoch 154, loss 0.10201, train_acc 0.9652, valid_acc 0.9541, Time 00:03:54,lr 0.010000000000000002\r\n",
      "epoch 155, loss 0.09617, train_acc 0.9680, valid_acc 0.9521, Time 00:03:51,lr 0.010000000000000002\r\n",
      "epoch 156, loss 0.09114, train_acc 0.9699, valid_acc 0.9549, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 157, loss 0.08635, train_acc 0.9705, valid_acc 0.9541, Time 00:03:54,lr 0.010000000000000002\r\n",
      "epoch 158, loss 0.08334, train_acc 0.9712, valid_acc 0.9537, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 159, loss 0.08333, train_acc 0.9727, valid_acc 0.9543, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 160, loss 0.07583, train_acc 0.9748, valid_acc 0.9574, Time 00:03:51,lr 0.010000000000000002\r\n",
      "epoch 161, loss 0.07276, train_acc 0.9758, valid_acc 0.9574, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 162, loss 0.07446, train_acc 0.9757, valid_acc 0.9541, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 163, loss 0.07101, train_acc 0.9759, valid_acc 0.9568, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 164, loss 0.06847, train_acc 0.9766, valid_acc 0.9547, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 165, loss 0.06918, train_acc 0.9775, valid_acc 0.9570, Time 00:03:55,lr 0.010000000000000002\r\n",
      "epoch 166, loss 0.06640, train_acc 0.9777, valid_acc 0.9576, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 167, loss 0.06313, train_acc 0.9793, valid_acc 0.9578, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 168, loss 0.06371, train_acc 0.9790, valid_acc 0.9535, Time 00:03:54,lr 0.010000000000000002\r\n",
      "epoch 169, loss 0.06079, train_acc 0.9798, valid_acc 0.9506, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 170, loss 0.06183, train_acc 0.9792, valid_acc 0.9572, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 171, loss 0.06081, train_acc 0.9793, valid_acc 0.9586, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 172, loss 0.06007, train_acc 0.9801, valid_acc 0.9547, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 173, loss 0.05753, train_acc 0.9811, valid_acc 0.9557, Time 00:03:55,lr 0.010000000000000002\r\n",
      "epoch 174, loss 0.05734, train_acc 0.9813, valid_acc 0.9578, Time 00:03:54,lr 0.010000000000000002\r\n",
      "epoch 175, loss 0.05598, train_acc 0.9815, valid_acc 0.9553, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 176, loss 0.05500, train_acc 0.9813, valid_acc 0.9584, Time 00:03:51,lr 0.010000000000000002\r\n",
      "epoch 177, loss 0.05509, train_acc 0.9819, valid_acc 0.9570, Time 00:04:02,lr 0.010000000000000002\r\n",
      "epoch 178, loss 0.05520, train_acc 0.9813, valid_acc 0.9568, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 179, loss 0.05068, train_acc 0.9836, valid_acc 0.9561, Time 00:03:56,lr 0.010000000000000002\r\n",
      "epoch 180, loss 0.05268, train_acc 0.9825, valid_acc 0.9566, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 181, loss 0.05211, train_acc 0.9831, valid_acc 0.9568, Time 00:03:54,lr 0.010000000000000002\r\n",
      "epoch 182, loss 0.05047, train_acc 0.9833, valid_acc 0.9533, Time 00:03:51,lr 0.010000000000000002\r\n",
      "epoch 183, loss 0.05026, train_acc 0.9824, valid_acc 0.9514, Time 00:03:51,lr 0.010000000000000002\r\n",
      "epoch 184, loss 0.05090, train_acc 0.9831, valid_acc 0.9535, Time 00:04:09,lr 0.010000000000000002\r\n",
      "epoch 185, loss 0.04804, train_acc 0.9839, valid_acc 0.9557, Time 00:03:55,lr 0.010000000000000002\r\n",
      "epoch 186, loss 0.04821, train_acc 0.9843, valid_acc 0.9539, Time 00:03:55,lr 0.010000000000000002\r\n",
      "epoch 187, loss 0.04711, train_acc 0.9852, valid_acc 0.9514, Time 00:03:59,lr 0.010000000000000002\r\n",
      "epoch 188, loss 0.04943, train_acc 0.9838, valid_acc 0.9553, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 189, loss 0.04703, train_acc 0.9843, valid_acc 0.9523, Time 00:03:49,lr 0.010000000000000002\r\n",
      "epoch 190, loss 0.04831, train_acc 0.9846, valid_acc 0.9482, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 191, loss 0.04633, train_acc 0.9843, valid_acc 0.9566, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 192, loss 0.04764, train_acc 0.9846, valid_acc 0.9553, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 193, loss 0.04706, train_acc 0.9847, valid_acc 0.9482, Time 00:03:50,lr 0.010000000000000002\r\n",
      "epoch 194, loss 0.04626, train_acc 0.9846, valid_acc 0.9512, Time 00:03:54,lr 0.010000000000000002\r\n",
      "epoch 195, loss 0.04825, train_acc 0.9847, valid_acc 0.9539, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 196, loss 0.04582, train_acc 0.9848, valid_acc 0.9553, Time 00:03:56,lr 0.010000000000000002\r\n",
      "epoch 197, loss 0.04412, train_acc 0.9854, valid_acc 0.9498, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 198, loss 0.04682, train_acc 0.9843, valid_acc 0.9527, Time 00:03:55,lr 0.010000000000000002\r\n",
      "epoch 199, loss 0.04384, train_acc 0.9858, valid_acc 0.9531, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 200, loss 0.04363, train_acc 0.9856, valid_acc 0.9559, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 201, loss 0.04126, train_acc 0.9865, valid_acc 0.9518, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 202, loss 0.04292, train_acc 0.9858, valid_acc 0.9535, Time 00:03:51,lr 0.010000000000000002\r\n",
      "epoch 203, loss 0.04087, train_acc 0.9867, valid_acc 0.9523, Time 00:03:51,lr 0.010000000000000002\r\n",
      "epoch 204, loss 0.04216, train_acc 0.9862, valid_acc 0.9543, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 205, loss 0.04006, train_acc 0.9870, valid_acc 0.9518, Time 00:03:50,lr 0.010000000000000002\r\n",
      "epoch 206, loss 0.04168, train_acc 0.9864, valid_acc 0.9537, Time 00:03:59,lr 0.010000000000000002\r\n",
      "epoch 207, loss 0.04440, train_acc 0.9854, valid_acc 0.9555, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 208, loss 0.04425, train_acc 0.9861, valid_acc 0.9549, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 209, loss 0.04196, train_acc 0.9863, valid_acc 0.9480, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 210, loss 0.04250, train_acc 0.9858, valid_acc 0.9520, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 211, loss 0.04219, train_acc 0.9858, valid_acc 0.9529, Time 00:03:55,lr 0.010000000000000002\r\n",
      "epoch 212, loss 0.04133, train_acc 0.9866, valid_acc 0.9521, Time 00:03:59,lr 0.010000000000000002\r\n",
      "epoch 213, loss 0.04090, train_acc 0.9867, valid_acc 0.9492, Time 00:03:49,lr 0.010000000000000002\r\n",
      "epoch 214, loss 0.04216, train_acc 0.9863, valid_acc 0.9545, Time 00:03:47,lr 0.010000000000000002\r\n",
      "epoch 215, loss 0.04406, train_acc 0.9857, valid_acc 0.9539, Time 00:03:50,lr 0.010000000000000002\r\n",
      "epoch 216, loss 0.04031, train_acc 0.9866, valid_acc 0.9553, Time 00:04:04,lr 0.010000000000000002\r\n",
      "epoch 217, loss 0.04136, train_acc 0.9866, valid_acc 0.9551, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 218, loss 0.04081, train_acc 0.9864, valid_acc 0.9551, Time 00:03:51,lr 0.010000000000000002\r\n",
      "epoch 219, loss 0.04081, train_acc 0.9867, valid_acc 0.9533, Time 00:03:50,lr 0.010000000000000002\r\n",
      "epoch 220, loss 0.03874, train_acc 0.9874, valid_acc 0.9457, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 221, loss 0.04168, train_acc 0.9864, valid_acc 0.9475, Time 00:03:50,lr 0.010000000000000002\r\n",
      "epoch 222, loss 0.04202, train_acc 0.9864, valid_acc 0.9529, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 223, loss 0.04054, train_acc 0.9868, valid_acc 0.9467, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 224, loss 0.04049, train_acc 0.9869, valid_acc 0.9436, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 225, loss 0.03712, train_acc 0.9877, valid_acc 0.9477, Time 00:03:49,lr 0.0010000000000000002\r\n",
      "epoch 226, loss 0.03258, train_acc 0.9896, valid_acc 0.9484, Time 00:04:02,lr 0.0010000000000000002\r\n",
      "epoch 227, loss 0.03043, train_acc 0.9902, valid_acc 0.9535, Time 00:03:53,lr 0.0010000000000000002\r\n",
      "epoch 228, loss 0.02943, train_acc 0.9906, valid_acc 0.9531, Time 00:03:57,lr 0.0010000000000000002\r\n",
      "epoch 229, loss 0.02793, train_acc 0.9914, valid_acc 0.9553, Time 00:03:52,lr 0.0010000000000000002\r\n",
      "epoch 230, loss 0.02718, train_acc 0.9917, valid_acc 0.9543, Time 00:03:59,lr 0.0010000000000000002\r\n",
      "epoch 231, loss 0.02787, train_acc 0.9913, valid_acc 0.9508, Time 00:03:52,lr 0.0010000000000000002\r\n",
      "epoch 232, loss 0.02887, train_acc 0.9908, valid_acc 0.9545, Time 00:03:57,lr 0.0010000000000000002\r\n",
      "epoch 233, loss 0.02656, train_acc 0.9923, valid_acc 0.9561, Time 00:03:54,lr 0.0010000000000000002\r\n",
      "epoch 234, loss 0.02581, train_acc 0.9917, valid_acc 0.9547, Time 00:04:00,lr 0.0010000000000000002\r\n",
      "epoch 235, loss 0.02604, train_acc 0.9920, valid_acc 0.9563, Time 00:03:53,lr 0.0010000000000000002\r\n",
      "epoch 236, loss 0.02570, train_acc 0.9921, valid_acc 0.9525, Time 00:03:58,lr 0.0010000000000000002\r\n",
      "epoch 237, loss 0.02533, train_acc 0.9921, valid_acc 0.9553, Time 00:03:56,lr 0.0010000000000000002\r\n",
      "epoch 238, loss 0.02454, train_acc 0.9926, valid_acc 0.9555, Time 00:04:01,lr 0.0010000000000000002\r\n",
      "epoch 239, loss 0.02605, train_acc 0.9919, valid_acc 0.9510, Time 00:03:52,lr 0.0010000000000000002\r\n",
      "epoch 240, loss 0.02522, train_acc 0.9922, valid_acc 0.9557, Time 00:04:02,lr 0.0010000000000000002\r\n",
      "epoch 241, loss 0.02507, train_acc 0.9918, valid_acc 0.9545, Time 00:03:51,lr 0.0010000000000000002\r\n",
      "epoch 242, loss 0.02421, train_acc 0.9923, valid_acc 0.9527, Time 00:03:50,lr 0.0010000000000000002\r\n",
      "epoch 243, loss 0.02286, train_acc 0.9932, valid_acc 0.9566, Time 00:03:52,lr 0.0010000000000000002\r\n",
      "epoch 244, loss 0.02319, train_acc 0.9927, valid_acc 0.9553, Time 00:04:00,lr 0.0010000000000000002\r\n",
      "epoch 245, loss 0.02286, train_acc 0.9933, valid_acc 0.9561, Time 00:03:55,lr 0.0010000000000000002\r\n",
      "epoch 246, loss 0.02256, train_acc 0.9930, valid_acc 0.9545, Time 00:03:50,lr 0.0010000000000000002\r\n",
      "epoch 247, loss 0.02362, train_acc 0.9923, valid_acc 0.9561, Time 00:03:52,lr 0.0010000000000000002\r\n",
      "epoch 248, loss 0.02381, train_acc 0.9926, valid_acc 0.9551, Time 00:03:52,lr 0.0010000000000000002\r\n",
      "epoch 249, loss 0.02235, train_acc 0.9931, valid_acc 0.9549, Time 00:03:49,lr 0.0010000000000000002\r\n",
      "epoch 250, loss 0.02432, train_acc 0.9923, valid_acc 0.9533, Time 00:03:50,lr 0.0010000000000000002\r\n",
      "epoch 251, loss 0.02454, train_acc 0.9924, valid_acc 0.9547, Time 00:03:51,lr 0.0010000000000000002\r\n",
      "epoch 252, loss 0.02259, train_acc 0.9930, valid_acc 0.9512, Time 00:03:58,lr 0.0010000000000000002\r\n",
      "epoch 253, loss 0.02285, train_acc 0.9930, valid_acc 0.9564, Time 00:03:52,lr 0.0010000000000000002\r\n",
      "epoch 254, loss 0.02337, train_acc 0.9926, valid_acc 0.9563, Time 00:03:54,lr 0.0010000000000000002\r\n",
      "epoch 255, loss 0.02284, train_acc 0.9927, valid_acc 0.9506, Time 00:03:55,lr 0.0010000000000000002\r\n",
      "epoch 256, loss 0.02250, train_acc 0.9932, valid_acc 0.9563, Time 00:03:51,lr 0.0010000000000000002\r\n",
      "epoch 257, loss 0.02176, train_acc 0.9936, valid_acc 0.9559, Time 00:03:57,lr 0.0010000000000000002\r\n",
      "epoch 258, loss 0.02234, train_acc 0.9929, valid_acc 0.9568, Time 00:03:52,lr 0.0010000000000000002\r\n",
      "epoch 259, loss 0.02194, train_acc 0.9933, valid_acc 0.9553, Time 00:03:51,lr 0.0010000000000000002\r\n",
      "epoch 260, loss 0.02209, train_acc 0.9930, valid_acc 0.9566, Time 00:03:56,lr 0.0010000000000000002\r\n",
      "epoch 261, loss 0.02243, train_acc 0.9931, valid_acc 0.9566, Time 00:03:50,lr 0.0010000000000000002\r\n",
      "epoch 262, loss 0.02323, train_acc 0.9925, valid_acc 0.9551, Time 00:03:59,lr 0.0010000000000000002\r\n",
      "epoch 263, loss 0.02036, train_acc 0.9939, valid_acc 0.9549, Time 00:03:53,lr 0.0010000000000000002\r\n",
      "epoch 264, loss 0.02126, train_acc 0.9935, valid_acc 0.9525, Time 00:03:51,lr 0.0010000000000000002\r\n",
      "epoch 265, loss 0.02012, train_acc 0.9938, valid_acc 0.9531, Time 00:03:52,lr 0.0010000000000000002\r\n",
      "epoch 266, loss 0.02240, train_acc 0.9927, valid_acc 0.9557, Time 00:03:53,lr 0.0010000000000000002\r\n",
      "epoch 267, loss 0.02118, train_acc 0.9936, valid_acc 0.9563, Time 00:03:54,lr 0.0010000000000000002\r\n",
      "epoch 268, loss 0.02018, train_acc 0.9940, valid_acc 0.9557, Time 00:03:58,lr 0.0010000000000000002\r\n",
      "epoch 269, loss 0.02027, train_acc 0.9939, valid_acc 0.9559, Time 00:03:58,lr 0.0010000000000000002\r\n",
      "epoch 270, loss 0.02193, train_acc 0.9929, valid_acc 0.9516, Time 00:04:02,lr 0.0010000000000000002\r\n",
      "epoch 271, loss 0.02285, train_acc 0.9933, valid_acc 0.9553, Time 00:04:04,lr 0.0010000000000000002\r\n",
      "epoch 272, loss 0.02130, train_acc 0.9934, valid_acc 0.9547, Time 00:03:56,lr 0.0010000000000000002\r\n",
      "epoch 273, loss 0.02171, train_acc 0.9934, valid_acc 0.9527, Time 00:03:50,lr 0.0010000000000000002\r\n",
      "epoch 274, loss 0.02101, train_acc 0.9934, valid_acc 0.9521, Time 00:03:56,lr 0.0010000000000000002\r\n",
      "epoch 275, loss 0.02097, train_acc 0.9938, valid_acc 0.9561, Time 00:03:47,lr 0.0010000000000000002\r\n",
      "epoch 276, loss 0.01986, train_acc 0.9939, valid_acc 0.9557, Time 00:03:50,lr 0.0010000000000000002\r\n",
      "epoch 277, loss 0.02060, train_acc 0.9934, valid_acc 0.9547, Time 00:03:54,lr 0.0010000000000000002\r\n",
      "epoch 278, loss 0.02057, train_acc 0.9941, valid_acc 0.9561, Time 00:03:52,lr 0.0010000000000000002\r\n",
      "epoch 279, loss 0.02057, train_acc 0.9938, valid_acc 0.9533, Time 00:03:53,lr 0.0010000000000000002\r\n",
      "epoch 280, loss 0.02046, train_acc 0.9938, valid_acc 0.9566, Time 00:03:47,lr 0.0010000000000000002\r\n",
      "epoch 281, loss 0.02147, train_acc 0.9933, valid_acc 0.9529, Time 00:03:49,lr 0.0010000000000000002\r\n",
      "epoch 282, loss 0.02139, train_acc 0.9931, valid_acc 0.9535, Time 00:03:54,lr 0.0010000000000000002\r\n",
      "epoch 283, loss 0.01961, train_acc 0.9940, valid_acc 0.9555, Time 00:03:51,lr 0.0010000000000000002\r\n",
      "epoch 284, loss 0.01955, train_acc 0.9942, valid_acc 0.9523, Time 00:03:50,lr 0.0010000000000000002\r\n",
      "epoch 285, loss 0.01937, train_acc 0.9942, valid_acc 0.9557, Time 00:03:58,lr 0.0010000000000000002\r\n",
      "epoch 286, loss 0.02057, train_acc 0.9938, valid_acc 0.9563, Time 00:03:56,lr 0.0010000000000000002\r\n",
      "epoch 287, loss 0.01901, train_acc 0.9943, valid_acc 0.9549, Time 00:03:48,lr 0.0010000000000000002\r\n",
      "epoch 288, loss 0.01962, train_acc 0.9940, valid_acc 0.9563, Time 00:03:48,lr 0.0010000000000000002\r\n",
      "epoch 289, loss 0.01951, train_acc 0.9937, valid_acc 0.9549, Time 00:04:06,lr 0.0010000000000000002\r\n",
      "epoch 290, loss 0.02001, train_acc 0.9942, valid_acc 0.9553, Time 00:03:57,lr 0.0010000000000000002\r\n",
      "epoch 291, loss 0.02002, train_acc 0.9936, valid_acc 0.9551, Time 00:03:56,lr 0.0010000000000000002\r\n",
      "epoch 292, loss 0.02012, train_acc 0.9936, valid_acc 0.9549, Time 00:03:57,lr 0.0010000000000000002\r\n",
      "epoch 293, loss 0.01927, train_acc 0.9945, valid_acc 0.9514, Time 00:03:55,lr 0.0010000000000000002\r\n",
      "epoch 294, loss 0.02135, train_acc 0.9931, valid_acc 0.9525, Time 00:03:56,lr 0.0010000000000000002\r\n",
      "epoch 295, loss 0.01916, train_acc 0.9939, valid_acc 0.9520, Time 00:04:02,lr 0.0010000000000000002\r\n",
      "epoch 296, loss 0.01832, train_acc 0.9942, valid_acc 0.9553, Time 00:03:56,lr 0.0010000000000000002\r\n",
      "epoch 297, loss 0.01959, train_acc 0.9941, valid_acc 0.9563, Time 00:03:56,lr 0.0010000000000000002\r\n",
      "epoch 298, loss 0.02039, train_acc 0.9935, valid_acc 0.9566, Time 00:03:53,lr 0.0010000000000000002\r\n",
      "epoch 299, loss 0.01925, train_acc 0.9943, valid_acc 0.9555, Time 00:03:54,lr 0.0010000000000000002\r\n",
      "epoch 0, loss 1.54863, train_acc 0.2469, valid_acc 0.3678, Time 00:03:45,lr 0.1\r\n",
      "epoch 1, loss 1.14262, train_acc 0.4111, valid_acc 0.4889, Time 00:03:59,lr 0.1\r\n",
      "epoch 2, loss 0.89502, train_acc 0.5163, valid_acc 0.5086, Time 00:03:55,lr 0.1\r\n",
      "epoch 3, loss 0.75679, train_acc 0.5770, valid_acc 0.6807, Time 00:04:00,lr 0.1\r\n",
      "epoch 4, loss 0.67095, train_acc 0.6232, valid_acc 0.7180, Time 00:04:02,lr 0.1\r\n",
      "epoch 5, loss 0.60276, train_acc 0.6590, valid_acc 0.7355, Time 00:03:56,lr 0.1\r\n",
      "epoch 6, loss 0.56324, train_acc 0.6775, valid_acc 0.7148, Time 00:03:58,lr 0.1\r\n",
      "epoch 7, loss 0.52872, train_acc 0.6927, valid_acc 0.7553, Time 00:03:58,lr 0.1\r\n",
      "epoch 8, loss 0.49612, train_acc 0.7117, valid_acc 0.7893, Time 00:04:07,lr 0.1\r\n",
      "epoch 9, loss 0.47507, train_acc 0.7220, valid_acc 0.7438, Time 00:04:01,lr 0.1\r\n",
      "epoch 10, loss 0.44853, train_acc 0.7342, valid_acc 0.7984, Time 00:03:54,lr 0.1\r\n",
      "epoch 11, loss 0.43769, train_acc 0.7399, valid_acc 0.8129, Time 00:03:54,lr 0.1\r\n",
      "epoch 12, loss 0.42922, train_acc 0.7436, valid_acc 0.8018, Time 00:03:52,lr 0.1\r\n",
      "epoch 13, loss 0.41009, train_acc 0.7520, valid_acc 0.7592, Time 00:04:10,lr 0.1\r\n",
      "epoch 14, loss 0.40366, train_acc 0.7603, valid_acc 0.7961, Time 00:04:04,lr 0.1\r\n",
      "epoch 15, loss 0.39068, train_acc 0.7650, valid_acc 0.8232, Time 00:03:56,lr 0.1\r\n",
      "epoch 16, loss 0.38170, train_acc 0.7706, valid_acc 0.8141, Time 00:03:56,lr 0.1\r\n",
      "epoch 17, loss 0.37474, train_acc 0.7737, valid_acc 0.8131, Time 00:03:57,lr 0.1\r\n",
      "epoch 18, loss 0.36968, train_acc 0.7739, valid_acc 0.8256, Time 00:03:59,lr 0.1\r\n",
      "epoch 19, loss 0.36424, train_acc 0.7784, valid_acc 0.8396, Time 00:03:55,lr 0.1\r\n",
      "epoch 20, loss 0.35346, train_acc 0.7849, valid_acc 0.8137, Time 00:03:59,lr 0.1\r\n",
      "epoch 21, loss 0.35044, train_acc 0.7884, valid_acc 0.8496, Time 00:03:55,lr 0.1\r\n",
      "epoch 22, loss 0.34558, train_acc 0.7895, valid_acc 0.8164, Time 00:04:00,lr 0.1\r\n",
      "epoch 23, loss 0.34092, train_acc 0.7916, valid_acc 0.8467, Time 00:04:03,lr 0.1\r\n",
      "epoch 24, loss 0.33428, train_acc 0.7956, valid_acc 0.8678, Time 00:03:58,lr 0.1\r\n",
      "epoch 25, loss 0.32869, train_acc 0.7975, valid_acc 0.8656, Time 00:03:59,lr 0.1\r\n",
      "epoch 26, loss 0.33199, train_acc 0.7975, valid_acc 0.8418, Time 00:03:54,lr 0.1\r\n",
      "epoch 27, loss 0.32329, train_acc 0.8011, valid_acc 0.8576, Time 00:04:09,lr 0.1\r\n",
      "epoch 28, loss 0.31590, train_acc 0.8060, valid_acc 0.8666, Time 00:03:56,lr 0.1\r\n",
      "epoch 29, loss 0.31353, train_acc 0.8064, valid_acc 0.8467, Time 00:04:03,lr 0.1\r\n",
      "epoch 30, loss 0.31065, train_acc 0.8084, valid_acc 0.8617, Time 00:03:58,lr 0.1\r\n",
      "epoch 31, loss 0.31750, train_acc 0.8063, valid_acc 0.8637, Time 00:03:55,lr 0.1\r\n",
      "epoch 32, loss 0.30797, train_acc 0.8108, valid_acc 0.8693, Time 00:03:55,lr 0.1\r\n",
      "epoch 33, loss 0.30434, train_acc 0.8128, valid_acc 0.8627, Time 00:03:57,lr 0.1\r\n",
      "epoch 34, loss 0.30332, train_acc 0.8124, valid_acc 0.8797, Time 00:03:59,lr 0.1\r\n",
      "epoch 35, loss 0.30213, train_acc 0.8118, valid_acc 0.8807, Time 00:04:00,lr 0.1\r\n",
      "epoch 36, loss 0.30051, train_acc 0.8151, valid_acc 0.8461, Time 00:03:58,lr 0.1\r\n",
      "epoch 37, loss 0.30412, train_acc 0.8121, valid_acc 0.8777, Time 00:03:57,lr 0.1\r\n",
      "epoch 38, loss 0.29265, train_acc 0.8172, valid_acc 0.8709, Time 00:03:59,lr 0.1\r\n",
      "epoch 39, loss 0.29518, train_acc 0.8166, valid_acc 0.8773, Time 00:03:57,lr 0.1\r\n",
      "epoch 40, loss 0.28822, train_acc 0.8205, valid_acc 0.8807, Time 00:03:56,lr 0.1\r\n",
      "epoch 41, loss 0.29386, train_acc 0.8170, valid_acc 0.8613, Time 00:03:57,lr 0.1\r\n",
      "epoch 42, loss 0.29633, train_acc 0.8184, valid_acc 0.8801, Time 00:03:59,lr 0.1\r\n",
      "epoch 43, loss 0.29572, train_acc 0.8181, valid_acc 0.8688, Time 00:03:58,lr 0.1\r\n",
      "epoch 44, loss 0.29428, train_acc 0.8199, valid_acc 0.8676, Time 00:03:59,lr 0.1\r\n",
      "epoch 45, loss 0.29496, train_acc 0.8157, valid_acc 0.8756, Time 00:04:03,lr 0.1\r\n",
      "epoch 46, loss 0.28388, train_acc 0.8230, valid_acc 0.8705, Time 00:03:55,lr 0.1\r\n",
      "epoch 47, loss 0.28468, train_acc 0.8224, valid_acc 0.8898, Time 00:03:56,lr 0.1\r\n",
      "epoch 48, loss 0.28713, train_acc 0.8235, valid_acc 0.8711, Time 00:03:56,lr 0.1\r\n",
      "epoch 49, loss 0.27864, train_acc 0.8269, valid_acc 0.8689, Time 00:03:57,lr 0.1\r\n",
      "epoch 50, loss 0.28361, train_acc 0.8233, valid_acc 0.8623, Time 00:03:59,lr 0.1\r\n",
      "epoch 51, loss 0.28352, train_acc 0.8236, valid_acc 0.8766, Time 00:04:00,lr 0.1\r\n",
      "epoch 52, loss 0.27860, train_acc 0.8267, valid_acc 0.8760, Time 00:03:57,lr 0.1\r\n",
      "epoch 53, loss 0.27820, train_acc 0.8285, valid_acc 0.8824, Time 00:03:57,lr 0.1\r\n",
      "epoch 54, loss 0.27621, train_acc 0.8271, valid_acc 0.8586, Time 00:03:59,lr 0.1\r\n",
      "epoch 55, loss 0.27841, train_acc 0.8267, valid_acc 0.8797, Time 00:03:57,lr 0.1\r\n",
      "epoch 56, loss 0.28100, train_acc 0.8264, valid_acc 0.8758, Time 00:03:55,lr 0.1\r\n",
      "epoch 57, loss 0.27915, train_acc 0.8290, valid_acc 0.8809, Time 00:03:58,lr 0.1\r\n",
      "epoch 58, loss 0.28100, train_acc 0.8268, valid_acc 0.8875, Time 00:03:55,lr 0.1\r\n",
      "epoch 59, loss 0.27151, train_acc 0.8302, valid_acc 0.8498, Time 00:03:56,lr 0.1\r\n",
      "epoch 60, loss 0.27401, train_acc 0.8300, valid_acc 0.8820, Time 00:03:59,lr 0.1\r\n",
      "epoch 61, loss 0.27803, train_acc 0.8276, valid_acc 0.8912, Time 00:04:02,lr 0.1\r\n",
      "epoch 62, loss 0.27250, train_acc 0.8301, valid_acc 0.8830, Time 00:03:57,lr 0.1\r\n",
      "epoch 63, loss 0.26905, train_acc 0.8325, valid_acc 0.8695, Time 00:03:55,lr 0.1\r\n",
      "epoch 64, loss 0.27162, train_acc 0.8318, valid_acc 0.8721, Time 00:04:03,lr 0.1\r\n",
      "epoch 65, loss 0.27209, train_acc 0.8306, valid_acc 0.8861, Time 00:03:56,lr 0.1\r\n",
      "epoch 66, loss 0.26868, train_acc 0.8317, valid_acc 0.8914, Time 00:03:56,lr 0.1\r\n",
      "epoch 67, loss 0.26467, train_acc 0.8349, valid_acc 0.8408, Time 00:04:03,lr 0.1\r\n",
      "epoch 68, loss 0.27097, train_acc 0.8321, valid_acc 0.8705, Time 00:03:59,lr 0.1\r\n",
      "epoch 69, loss 0.27383, train_acc 0.8290, valid_acc 0.8793, Time 00:03:56,lr 0.1\r\n",
      "epoch 70, loss 0.26958, train_acc 0.8323, valid_acc 0.9018, Time 00:03:55,lr 0.1\r\n",
      "epoch 71, loss 0.26580, train_acc 0.8324, valid_acc 0.8971, Time 00:03:55,lr 0.1\r\n",
      "epoch 72, loss 0.26764, train_acc 0.8346, valid_acc 0.8820, Time 00:03:57,lr 0.1\r\n",
      "epoch 73, loss 0.26335, train_acc 0.8357, valid_acc 0.8668, Time 00:03:55,lr 0.1\r\n",
      "epoch 74, loss 0.26697, train_acc 0.8329, valid_acc 0.8828, Time 00:04:05,lr 0.1\r\n",
      "epoch 75, loss 0.26430, train_acc 0.8331, valid_acc 0.8734, Time 00:04:05,lr 0.1\r\n",
      "epoch 76, loss 0.26136, train_acc 0.8374, valid_acc 0.8861, Time 00:03:54,lr 0.1\r\n",
      "epoch 77, loss 0.25918, train_acc 0.8363, valid_acc 0.8705, Time 00:04:07,lr 0.1\r\n",
      "epoch 78, loss 0.25911, train_acc 0.8381, valid_acc 0.8906, Time 00:03:56,lr 0.1\r\n",
      "epoch 79, loss 0.26604, train_acc 0.8334, valid_acc 0.8771, Time 00:04:02,lr 0.1\r\n",
      "epoch 80, loss 0.26103, train_acc 0.8372, valid_acc 0.8865, Time 00:04:00,lr 0.1\r\n",
      "epoch 81, loss 0.25987, train_acc 0.8371, valid_acc 0.8844, Time 00:04:08,lr 0.1\r\n",
      "epoch 82, loss 0.25876, train_acc 0.8385, valid_acc 0.8850, Time 00:03:57,lr 0.1\r\n",
      "epoch 83, loss 0.25957, train_acc 0.8383, valid_acc 0.8775, Time 00:03:59,lr 0.1\r\n",
      "epoch 84, loss 0.25646, train_acc 0.8414, valid_acc 0.8787, Time 00:03:55,lr 0.1\r\n",
      "epoch 85, loss 0.25829, train_acc 0.8389, valid_acc 0.8824, Time 00:03:59,lr 0.1\r\n",
      "epoch 86, loss 0.25095, train_acc 0.8433, valid_acc 0.8840, Time 00:03:55,lr 0.1\r\n",
      "epoch 87, loss 0.25118, train_acc 0.8437, valid_acc 0.8920, Time 00:03:57,lr 0.1\r\n",
      "epoch 88, loss 0.25565, train_acc 0.8398, valid_acc 0.8912, Time 00:03:54,lr 0.1\r\n",
      "epoch 89, loss 0.25264, train_acc 0.8419, valid_acc 0.8695, Time 00:03:56,lr 0.1\r\n",
      "epoch 90, loss 0.25528, train_acc 0.8411, valid_acc 0.8998, Time 00:03:55,lr 0.1\r\n",
      "epoch 91, loss 0.25483, train_acc 0.8402, valid_acc 0.8818, Time 00:03:56,lr 0.1\r\n",
      "epoch 92, loss 0.25751, train_acc 0.8390, valid_acc 0.8797, Time 00:03:57,lr 0.1\r\n",
      "epoch 93, loss 0.25410, train_acc 0.8411, valid_acc 0.8953, Time 00:04:01,lr 0.1\r\n",
      "epoch 94, loss 0.24966, train_acc 0.8410, valid_acc 0.8947, Time 00:04:01,lr 0.1\r\n",
      "epoch 95, loss 0.25077, train_acc 0.8416, valid_acc 0.8895, Time 00:03:59,lr 0.1\r\n",
      "epoch 96, loss 0.25410, train_acc 0.8404, valid_acc 0.8732, Time 00:03:58,lr 0.1\r\n",
      "epoch 97, loss 0.24691, train_acc 0.8468, valid_acc 0.8826, Time 00:03:57,lr 0.1\r\n",
      "epoch 98, loss 0.25532, train_acc 0.8414, valid_acc 0.8791, Time 00:03:58,lr 0.1\r\n",
      "epoch 99, loss 0.25105, train_acc 0.8418, valid_acc 0.8814, Time 00:04:00,lr 0.1\r\n",
      "epoch 100, loss 0.24579, train_acc 0.8449, valid_acc 0.8994, Time 00:03:59,lr 0.1\r\n",
      "epoch 101, loss 0.24953, train_acc 0.8429, valid_acc 0.8879, Time 00:03:57,lr 0.1\r\n",
      "epoch 102, loss 0.24073, train_acc 0.8486, valid_acc 0.8881, Time 00:03:58,lr 0.1\r\n",
      "epoch 103, loss 0.23807, train_acc 0.8492, valid_acc 0.8836, Time 00:03:56,lr 0.1\r\n",
      "epoch 104, loss 0.24675, train_acc 0.8445, valid_acc 0.8885, Time 00:03:56,lr 0.1\r\n",
      "epoch 105, loss 0.24587, train_acc 0.8445, valid_acc 0.8854, Time 00:03:55,lr 0.1\r\n",
      "epoch 106, loss 0.24795, train_acc 0.8448, valid_acc 0.8900, Time 00:03:56,lr 0.1\r\n",
      "epoch 107, loss 0.24435, train_acc 0.8463, valid_acc 0.8988, Time 00:04:01,lr 0.1\r\n",
      "epoch 108, loss 0.24298, train_acc 0.8455, valid_acc 0.8955, Time 00:03:58,lr 0.1\r\n",
      "epoch 109, loss 0.24506, train_acc 0.8467, valid_acc 0.9074, Time 00:04:01,lr 0.1\r\n",
      "epoch 110, loss 0.24395, train_acc 0.8490, valid_acc 0.8916, Time 00:04:02,lr 0.1\r\n",
      "epoch 111, loss 0.24303, train_acc 0.8457, valid_acc 0.9021, Time 00:03:59,lr 0.1\r\n",
      "epoch 112, loss 0.24210, train_acc 0.8461, valid_acc 0.8779, Time 00:03:55,lr 0.1\r\n",
      "epoch 113, loss 0.24508, train_acc 0.8461, valid_acc 0.8848, Time 00:03:56,lr 0.1\r\n",
      "epoch 114, loss 0.23799, train_acc 0.8511, valid_acc 0.9064, Time 00:03:57,lr 0.1\r\n",
      "epoch 115, loss 0.24107, train_acc 0.8488, valid_acc 0.9021, Time 00:03:57,lr 0.1\r\n",
      "epoch 116, loss 0.23791, train_acc 0.8477, valid_acc 0.9084, Time 00:04:00,lr 0.1\r\n",
      "epoch 117, loss 0.23636, train_acc 0.8488, valid_acc 0.8938, Time 00:03:55,lr 0.1\r\n",
      "epoch 118, loss 0.24184, train_acc 0.8486, valid_acc 0.8869, Time 00:03:58,lr 0.1\r\n",
      "epoch 119, loss 0.24439, train_acc 0.8474, valid_acc 0.8842, Time 00:03:59,lr 0.1\r\n",
      "epoch 120, loss 0.24066, train_acc 0.8486, valid_acc 0.8893, Time 00:04:03,lr 0.1\r\n",
      "epoch 121, loss 0.23873, train_acc 0.8480, valid_acc 0.8971, Time 00:04:02,lr 0.1\r\n",
      "epoch 122, loss 0.24061, train_acc 0.8478, valid_acc 0.8920, Time 00:04:02,lr 0.1\r\n",
      "epoch 123, loss 0.23995, train_acc 0.8501, valid_acc 0.8867, Time 00:04:03,lr 0.1\r\n",
      "epoch 124, loss 0.23340, train_acc 0.8490, valid_acc 0.8914, Time 00:03:56,lr 0.1\r\n",
      "epoch 125, loss 0.23840, train_acc 0.8494, valid_acc 0.8904, Time 00:03:59,lr 0.1\r\n",
      "epoch 126, loss 0.24008, train_acc 0.8509, valid_acc 0.9031, Time 00:03:56,lr 0.1\r\n",
      "epoch 127, loss 0.23612, train_acc 0.8504, valid_acc 0.8955, Time 00:03:58,lr 0.1\r\n",
      "epoch 128, loss 0.23547, train_acc 0.8515, valid_acc 0.8947, Time 00:04:01,lr 0.1\r\n",
      "epoch 129, loss 0.23152, train_acc 0.8530, valid_acc 0.8760, Time 00:03:55,lr 0.1\r\n",
      "epoch 130, loss 0.23752, train_acc 0.8499, valid_acc 0.8773, Time 00:03:58,lr 0.1\r\n",
      "epoch 131, loss 0.23569, train_acc 0.8521, valid_acc 0.8902, Time 00:03:56,lr 0.1\r\n",
      "epoch 132, loss 0.23628, train_acc 0.8505, valid_acc 0.9148, Time 00:03:56,lr 0.1\r\n",
      "epoch 133, loss 0.24290, train_acc 0.8473, valid_acc 0.8863, Time 00:03:58,lr 0.1\r\n",
      "epoch 134, loss 0.23472, train_acc 0.8502, valid_acc 0.8959, Time 00:03:55,lr 0.1\r\n",
      "epoch 135, loss 0.23295, train_acc 0.8524, valid_acc 0.9016, Time 00:03:56,lr 0.1\r\n",
      "epoch 136, loss 0.23714, train_acc 0.8496, valid_acc 0.8857, Time 00:03:56,lr 0.1\r\n",
      "epoch 137, loss 0.23597, train_acc 0.8511, valid_acc 0.9100, Time 00:03:57,lr 0.1\r\n",
      "epoch 138, loss 0.23162, train_acc 0.8522, valid_acc 0.8855, Time 00:03:55,lr 0.1\r\n",
      "epoch 139, loss 0.23497, train_acc 0.8511, valid_acc 0.8951, Time 00:03:57,lr 0.1\r\n",
      "epoch 140, loss 0.23639, train_acc 0.8529, valid_acc 0.9049, Time 00:03:58,lr 0.1\r\n",
      "epoch 141, loss 0.23484, train_acc 0.8514, valid_acc 0.8820, Time 00:03:56,lr 0.1\r\n",
      "epoch 142, loss 0.23060, train_acc 0.8535, valid_acc 0.8879, Time 00:03:59,lr 0.1\r\n",
      "epoch 143, loss 0.23292, train_acc 0.8518, valid_acc 0.8812, Time 00:03:55,lr 0.1\r\n",
      "epoch 144, loss 0.23327, train_acc 0.8510, valid_acc 0.8959, Time 00:03:57,lr 0.1\r\n",
      "epoch 145, loss 0.23348, train_acc 0.8506, valid_acc 0.8910, Time 00:03:54,lr 0.1\r\n",
      "epoch 146, loss 0.22935, train_acc 0.8550, valid_acc 0.8824, Time 00:03:56,lr 0.1\r\n",
      "epoch 147, loss 0.23044, train_acc 0.8533, valid_acc 0.9078, Time 00:03:56,lr 0.1\r\n",
      "epoch 148, loss 0.22884, train_acc 0.8559, valid_acc 0.8893, Time 00:03:57,lr 0.1\r\n",
      "epoch 149, loss 0.23231, train_acc 0.8514, valid_acc 0.8963, Time 00:04:02,lr 0.1\r\n",
      "epoch 150, loss 0.16879, train_acc 0.8882, valid_acc 0.9348, Time 00:03:56,lr 0.010000000000000002\r\n",
      "epoch 151, loss 0.13615, train_acc 0.9098, valid_acc 0.9412, Time 00:03:56,lr 0.010000000000000002\r\n",
      "epoch 152, loss 0.12580, train_acc 0.9170, valid_acc 0.9400, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 153, loss 0.12292, train_acc 0.9206, valid_acc 0.9437, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 154, loss 0.11630, train_acc 0.9218, valid_acc 0.9447, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 155, loss 0.11312, train_acc 0.9261, valid_acc 0.9437, Time 00:03:56,lr 0.010000000000000002\r\n",
      "epoch 156, loss 0.11002, train_acc 0.9261, valid_acc 0.9465, Time 00:03:54,lr 0.010000000000000002\r\n",
      "epoch 157, loss 0.10931, train_acc 0.9269, valid_acc 0.9482, Time 00:03:55,lr 0.010000000000000002\r\n",
      "epoch 158, loss 0.10529, train_acc 0.9301, valid_acc 0.9469, Time 00:03:55,lr 0.010000000000000002\r\n",
      "epoch 159, loss 0.10453, train_acc 0.9311, valid_acc 0.9492, Time 00:04:03,lr 0.010000000000000002\r\n",
      "epoch 160, loss 0.10563, train_acc 0.9304, valid_acc 0.9436, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 161, loss 0.09581, train_acc 0.9352, valid_acc 0.9461, Time 00:04:00,lr 0.010000000000000002\r\n",
      "epoch 162, loss 0.09985, train_acc 0.9349, valid_acc 0.9441, Time 00:04:02,lr 0.010000000000000002\r\n",
      "epoch 163, loss 0.09825, train_acc 0.9351, valid_acc 0.9508, Time 00:03:53,lr 0.010000000000000002\r\n",
      "epoch 164, loss 0.09728, train_acc 0.9357, valid_acc 0.9471, Time 00:03:59,lr 0.010000000000000002\r\n",
      "epoch 165, loss 0.09619, train_acc 0.9354, valid_acc 0.9449, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 166, loss 0.09588, train_acc 0.9353, valid_acc 0.9482, Time 00:03:59,lr 0.010000000000000002\r\n",
      "epoch 167, loss 0.09571, train_acc 0.9359, valid_acc 0.9482, Time 00:03:56,lr 0.010000000000000002\r\n",
      "epoch 168, loss 0.09843, train_acc 0.9359, valid_acc 0.9498, Time 00:03:56,lr 0.010000000000000002\r\n",
      "epoch 169, loss 0.09556, train_acc 0.9385, valid_acc 0.9449, Time 00:03:59,lr 0.010000000000000002\r\n",
      "epoch 170, loss 0.09501, train_acc 0.9386, valid_acc 0.9496, Time 00:03:56,lr 0.010000000000000002\r\n",
      "epoch 171, loss 0.09206, train_acc 0.9387, valid_acc 0.9490, Time 00:03:54,lr 0.010000000000000002\r\n",
      "epoch 172, loss 0.09456, train_acc 0.9375, valid_acc 0.9518, Time 00:04:06,lr 0.010000000000000002\r\n",
      "epoch 173, loss 0.08800, train_acc 0.9420, valid_acc 0.9508, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 174, loss 0.09095, train_acc 0.9411, valid_acc 0.9475, Time 00:03:55,lr 0.010000000000000002\r\n",
      "epoch 175, loss 0.08737, train_acc 0.9406, valid_acc 0.9475, Time 00:04:02,lr 0.010000000000000002\r\n",
      "epoch 176, loss 0.08866, train_acc 0.9408, valid_acc 0.9518, Time 00:03:59,lr 0.010000000000000002\r\n",
      "epoch 177, loss 0.08727, train_acc 0.9411, valid_acc 0.9479, Time 00:04:05,lr 0.010000000000000002\r\n",
      "epoch 178, loss 0.08843, train_acc 0.9426, valid_acc 0.9459, Time 00:03:59,lr 0.010000000000000002\r\n",
      "epoch 179, loss 0.08595, train_acc 0.9429, valid_acc 0.9479, Time 00:04:02,lr 0.010000000000000002\r\n",
      "epoch 180, loss 0.08696, train_acc 0.9437, valid_acc 0.9516, Time 00:04:05,lr 0.010000000000000002\r\n",
      "epoch 181, loss 0.08750, train_acc 0.9413, valid_acc 0.9455, Time 00:03:54,lr 0.010000000000000002\r\n",
      "epoch 182, loss 0.08797, train_acc 0.9430, valid_acc 0.9451, Time 00:03:54,lr 0.010000000000000002\r\n",
      "epoch 183, loss 0.08632, train_acc 0.9426, valid_acc 0.9463, Time 00:03:52,lr 0.010000000000000002\r\n",
      "epoch 184, loss 0.08610, train_acc 0.9431, valid_acc 0.9488, Time 00:03:54,lr 0.010000000000000002\r\n",
      "epoch 185, loss 0.08549, train_acc 0.9439, valid_acc 0.9510, Time 00:03:59,lr 0.010000000000000002\r\n",
      "epoch 186, loss 0.08546, train_acc 0.9446, valid_acc 0.9484, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 187, loss 0.08382, train_acc 0.9452, valid_acc 0.9500, Time 00:04:01,lr 0.010000000000000002\r\n",
      "epoch 188, loss 0.08263, train_acc 0.9455, valid_acc 0.9408, Time 00:04:01,lr 0.010000000000000002\r\n",
      "epoch 189, loss 0.08007, train_acc 0.9489, valid_acc 0.9494, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 190, loss 0.08296, train_acc 0.9458, valid_acc 0.9496, Time 00:04:01,lr 0.010000000000000002\r\n",
      "epoch 191, loss 0.08093, train_acc 0.9462, valid_acc 0.9424, Time 00:04:09,lr 0.010000000000000002\r\n",
      "epoch 192, loss 0.08159, train_acc 0.9460, valid_acc 0.9486, Time 00:04:01,lr 0.010000000000000002\r\n",
      "epoch 193, loss 0.08029, train_acc 0.9466, valid_acc 0.9494, Time 00:04:02,lr 0.010000000000000002\r\n",
      "epoch 194, loss 0.08106, train_acc 0.9466, valid_acc 0.9484, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 195, loss 0.07865, train_acc 0.9476, valid_acc 0.9516, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 196, loss 0.07964, train_acc 0.9466, valid_acc 0.9477, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 197, loss 0.08162, train_acc 0.9470, valid_acc 0.9510, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 198, loss 0.08382, train_acc 0.9449, valid_acc 0.9525, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 199, loss 0.08279, train_acc 0.9472, valid_acc 0.9496, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 200, loss 0.07807, train_acc 0.9487, valid_acc 0.9482, Time 00:04:04,lr 0.010000000000000002\r\n",
      "epoch 201, loss 0.08103, train_acc 0.9463, valid_acc 0.9533, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 202, loss 0.08216, train_acc 0.9466, valid_acc 0.9492, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 203, loss 0.07762, train_acc 0.9494, valid_acc 0.9494, Time 00:03:55,lr 0.010000000000000002\r\n",
      "epoch 204, loss 0.08111, train_acc 0.9474, valid_acc 0.9490, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 205, loss 0.07651, train_acc 0.9510, valid_acc 0.9498, Time 00:03:59,lr 0.010000000000000002\r\n",
      "epoch 206, loss 0.07833, train_acc 0.9488, valid_acc 0.9504, Time 00:03:54,lr 0.010000000000000002\r\n",
      "epoch 207, loss 0.07796, train_acc 0.9485, valid_acc 0.9480, Time 00:03:56,lr 0.010000000000000002\r\n",
      "epoch 208, loss 0.07700, train_acc 0.9500, valid_acc 0.9465, Time 00:04:00,lr 0.010000000000000002\r\n",
      "epoch 209, loss 0.07778, train_acc 0.9494, valid_acc 0.9467, Time 00:04:00,lr 0.010000000000000002\r\n",
      "epoch 210, loss 0.07493, train_acc 0.9503, valid_acc 0.9518, Time 00:04:00,lr 0.010000000000000002\r\n",
      "epoch 211, loss 0.07874, train_acc 0.9484, valid_acc 0.9447, Time 00:04:02,lr 0.010000000000000002\r\n",
      "epoch 212, loss 0.07489, train_acc 0.9522, valid_acc 0.9484, Time 00:04:18,lr 0.010000000000000002\r\n",
      "epoch 213, loss 0.07961, train_acc 0.9493, valid_acc 0.9514, Time 00:04:00,lr 0.010000000000000002\r\n",
      "epoch 214, loss 0.07896, train_acc 0.9490, valid_acc 0.9523, Time 00:04:02,lr 0.010000000000000002\r\n",
      "epoch 215, loss 0.07709, train_acc 0.9510, valid_acc 0.9512, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 216, loss 0.07627, train_acc 0.9516, valid_acc 0.9508, Time 00:03:56,lr 0.010000000000000002\r\n",
      "epoch 217, loss 0.07368, train_acc 0.9524, valid_acc 0.9500, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 218, loss 0.07939, train_acc 0.9496, valid_acc 0.9502, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 219, loss 0.07751, train_acc 0.9496, valid_acc 0.9451, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 220, loss 0.07683, train_acc 0.9489, valid_acc 0.9518, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 221, loss 0.07701, train_acc 0.9509, valid_acc 0.9516, Time 00:03:58,lr 0.010000000000000002\r\n",
      "epoch 222, loss 0.07631, train_acc 0.9512, valid_acc 0.9512, Time 00:03:56,lr 0.010000000000000002\r\n",
      "epoch 223, loss 0.07457, train_acc 0.9514, valid_acc 0.9479, Time 00:03:57,lr 0.010000000000000002\r\n",
      "epoch 224, loss 0.07729, train_acc 0.9506, valid_acc 0.9486, Time 00:04:03,lr 0.010000000000000002\r\n",
      "epoch 225, loss 0.07260, train_acc 0.9517, valid_acc 0.9518, Time 00:03:58,lr 0.0010000000000000002\r\n",
      "epoch 226, loss 0.06976, train_acc 0.9544, valid_acc 0.9537, Time 00:03:57,lr 0.0010000000000000002\r\n",
      "epoch 227, loss 0.07032, train_acc 0.9554, valid_acc 0.9506, Time 00:04:01,lr 0.0010000000000000002\r\n",
      "epoch 228, loss 0.06512, train_acc 0.9590, valid_acc 0.9518, Time 00:03:55,lr 0.0010000000000000002\r\n",
      "epoch 229, loss 0.06659, train_acc 0.9576, valid_acc 0.9539, Time 00:03:56,lr 0.0010000000000000002\r\n",
      "epoch 230, loss 0.06510, train_acc 0.9580, valid_acc 0.9514, Time 00:04:04,lr 0.0010000000000000002\r\n",
      "epoch 231, loss 0.06674, train_acc 0.9580, valid_acc 0.9506, Time 00:03:56,lr 0.0010000000000000002\r\n",
      "epoch 232, loss 0.06636, train_acc 0.9577, valid_acc 0.9539, Time 00:04:08,lr 0.0010000000000000002\r\n",
      "epoch 233, loss 0.06342, train_acc 0.9594, valid_acc 0.9553, Time 00:03:59,lr 0.0010000000000000002\r\n",
      "epoch 234, loss 0.06429, train_acc 0.9595, valid_acc 0.9521, Time 00:03:53,lr 0.0010000000000000002\r\n",
      "epoch 235, loss 0.06168, train_acc 0.9602, valid_acc 0.9561, Time 00:03:51,lr 0.0010000000000000002\r\n",
      "epoch 236, loss 0.06609, train_acc 0.9584, valid_acc 0.9547, Time 00:03:56,lr 0.0010000000000000002\r\n",
      "epoch 237, loss 0.06507, train_acc 0.9587, valid_acc 0.9568, Time 00:03:52,lr 0.0010000000000000002\r\n",
      "epoch 238, loss 0.06095, train_acc 0.9609, valid_acc 0.9502, Time 00:03:55,lr 0.0010000000000000002\r\n",
      "epoch 239, loss 0.06168, train_acc 0.9618, valid_acc 0.9564, Time 00:03:58,lr 0.0010000000000000002\r\n",
      "epoch 240, loss 0.06331, train_acc 0.9605, valid_acc 0.9559, Time 00:03:59,lr 0.0010000000000000002\r\n",
      "epoch 241, loss 0.06196, train_acc 0.9611, valid_acc 0.9549, Time 00:03:59,lr 0.0010000000000000002\r\n",
      "epoch 242, loss 0.06541, train_acc 0.9589, valid_acc 0.9514, Time 00:03:58,lr 0.0010000000000000002\r\n",
      "epoch 243, loss 0.06426, train_acc 0.9604, valid_acc 0.9561, Time 00:03:58,lr 0.0010000000000000002\r\n",
      "epoch 244, loss 0.06129, train_acc 0.9606, valid_acc 0.9564, Time 00:03:54,lr 0.0010000000000000002\r\n",
      "epoch 245, loss 0.06225, train_acc 0.9615, valid_acc 0.9561, Time 00:03:57,lr 0.0010000000000000002\r\n",
      "epoch 246, loss 0.06068, train_acc 0.9627, valid_acc 0.9514, Time 00:03:57,lr 0.0010000000000000002\r\n",
      "epoch 247, loss 0.06413, train_acc 0.9607, valid_acc 0.9555, Time 00:03:53,lr 0.0010000000000000002\r\n",
      "epoch 248, loss 0.06294, train_acc 0.9619, valid_acc 0.9570, Time 00:04:00,lr 0.0010000000000000002\r\n",
      "epoch 249, loss 0.06069, train_acc 0.9615, valid_acc 0.9568, Time 00:04:09,lr 0.0010000000000000002\r\n",
      "epoch 250, loss 0.06246, train_acc 0.9601, valid_acc 0.9555, Time 00:03:56,lr 0.0010000000000000002\r\n",
      "epoch 251, loss 0.06122, train_acc 0.9613, valid_acc 0.9516, Time 00:03:58,lr 0.0010000000000000002\r\n",
      "epoch 252, loss 0.06066, train_acc 0.9608, valid_acc 0.9543, Time 00:04:02,lr 0.0010000000000000002\r\n",
      "epoch 253, loss 0.06074, train_acc 0.9613, valid_acc 0.9490, Time 00:04:02,lr 0.0010000000000000002\r\n",
      "epoch 254, loss 0.06074, train_acc 0.9624, valid_acc 0.9510, Time 00:03:52,lr 0.0010000000000000002\r\n",
      "[04:33:57] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n",
      "[04:33:58] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n",
      "[04:36:12] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n",
      "[04:36:21] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n",
      "epoch 0, loss 1.52416, train_acc 0.4359, valid_acc 0.5459, Time 00:02:16,lr 0.1\r\n",
      "epoch 1, loss 1.03088, train_acc 0.6302, valid_acc 0.6443, Time 00:02:24,lr 0.1\r\n",
      "epoch 2, loss 0.82283, train_acc 0.7075, valid_acc 0.6840, Time 00:02:28,lr 0.1\r\n",
      "epoch 3, loss 0.69319, train_acc 0.7555, valid_acc 0.7016, Time 00:02:23,lr 0.1\r\n",
      "epoch 4, loss 0.60129, train_acc 0.7901, valid_acc 0.7578, Time 00:02:25,lr 0.1\r\n",
      "epoch 5, loss 0.53606, train_acc 0.8142, valid_acc 0.8037, Time 00:02:20,lr 0.1\r\n",
      "epoch 6, loss 0.49581, train_acc 0.8292, valid_acc 0.7914, Time 00:02:24,lr 0.1\r\n",
      "epoch 7, loss 0.45117, train_acc 0.8443, valid_acc 0.8238, Time 00:02:23,lr 0.1\r\n",
      "epoch 8, loss 0.42405, train_acc 0.8534, valid_acc 0.8215, Time 00:02:21,lr 0.1\r\n",
      "epoch 9, loss 0.39600, train_acc 0.8618, valid_acc 0.8281, Time 00:02:22,lr 0.1\r\n",
      "epoch 10, loss 0.37335, train_acc 0.8715, valid_acc 0.8219, Time 00:02:23,lr 0.1\r\n",
      "epoch 11, loss 0.35635, train_acc 0.8767, valid_acc 0.8289, Time 00:02:24,lr 0.1\r\n",
      "epoch 12, loss 0.33758, train_acc 0.8820, valid_acc 0.8338, Time 00:02:22,lr 0.1\r\n",
      "epoch 13, loss 0.32374, train_acc 0.8884, valid_acc 0.8566, Time 00:02:23,lr 0.1\r\n",
      "epoch 14, loss 0.30882, train_acc 0.8930, valid_acc 0.8320, Time 00:02:21,lr 0.1\r\n",
      "epoch 15, loss 0.30150, train_acc 0.8961, valid_acc 0.8463, Time 00:02:21,lr 0.1\r\n",
      "epoch 16, loss 0.29503, train_acc 0.8988, valid_acc 0.8508, Time 00:02:23,lr 0.1\r\n",
      "epoch 17, loss 0.28239, train_acc 0.9016, valid_acc 0.8551, Time 00:02:25,lr 0.1\r\n",
      "epoch 18, loss 0.26945, train_acc 0.9073, valid_acc 0.8748, Time 00:02:22,lr 0.1\r\n",
      "epoch 19, loss 0.26651, train_acc 0.9078, valid_acc 0.8805, Time 00:02:21,lr 0.1\r\n",
      "epoch 20, loss 0.25566, train_acc 0.9118, valid_acc 0.8457, Time 00:02:21,lr 0.1\r\n",
      "epoch 21, loss 0.24715, train_acc 0.9129, valid_acc 0.8738, Time 00:02:22,lr 0.1\r\n",
      "epoch 22, loss 0.24378, train_acc 0.9152, valid_acc 0.8682, Time 00:02:28,lr 0.1\r\n",
      "epoch 23, loss 0.23410, train_acc 0.9184, valid_acc 0.8459, Time 00:02:24,lr 0.1\r\n",
      "epoch 24, loss 0.22907, train_acc 0.9195, valid_acc 0.8830, Time 00:02:23,lr 0.1\r\n",
      "epoch 25, loss 0.22971, train_acc 0.9193, valid_acc 0.8580, Time 00:02:23,lr 0.1\r\n",
      "epoch 26, loss 0.22437, train_acc 0.9219, valid_acc 0.8457, Time 00:02:22,lr 0.1\r\n",
      "epoch 27, loss 0.22322, train_acc 0.9216, valid_acc 0.8471, Time 00:02:22,lr 0.1\r\n",
      "epoch 28, loss 0.21779, train_acc 0.9245, valid_acc 0.8805, Time 00:02:23,lr 0.1\r\n",
      "epoch 29, loss 0.21563, train_acc 0.9236, valid_acc 0.8758, Time 00:02:26,lr 0.1\r\n",
      "epoch 30, loss 0.20631, train_acc 0.9285, valid_acc 0.8740, Time 00:02:24,lr 0.1\r\n",
      "epoch 31, loss 0.20199, train_acc 0.9296, valid_acc 0.8633, Time 00:02:20,lr 0.1\r\n",
      "epoch 32, loss 0.20245, train_acc 0.9290, valid_acc 0.8668, Time 00:02:24,lr 0.1\r\n",
      "epoch 33, loss 0.19945, train_acc 0.9304, valid_acc 0.8838, Time 00:02:24,lr 0.1\r\n",
      "epoch 34, loss 0.20064, train_acc 0.9315, valid_acc 0.8500, Time 00:02:27,lr 0.1\r\n",
      "epoch 35, loss 0.19981, train_acc 0.9317, valid_acc 0.8807, Time 00:02:28,lr 0.1\r\n",
      "epoch 36, loss 0.19060, train_acc 0.9332, valid_acc 0.8697, Time 00:02:26,lr 0.1\r\n",
      "epoch 37, loss 0.19178, train_acc 0.9329, valid_acc 0.8754, Time 00:02:23,lr 0.1\r\n",
      "epoch 38, loss 0.18802, train_acc 0.9340, valid_acc 0.8449, Time 00:02:23,lr 0.1\r\n",
      "epoch 39, loss 0.19007, train_acc 0.9320, valid_acc 0.8520, Time 00:02:24,lr 0.1\r\n",
      "epoch 40, loss 0.18300, train_acc 0.9367, valid_acc 0.8736, Time 00:02:24,lr 0.1\r\n",
      "epoch 41, loss 0.18757, train_acc 0.9341, valid_acc 0.8672, Time 00:02:26,lr 0.1\r\n",
      "epoch 42, loss 0.18110, train_acc 0.9366, valid_acc 0.8957, Time 00:02:23,lr 0.1\r\n",
      "epoch 43, loss 0.18096, train_acc 0.9360, valid_acc 0.8875, Time 00:02:25,lr 0.1\r\n",
      "epoch 44, loss 0.17388, train_acc 0.9396, valid_acc 0.8977, Time 00:02:25,lr 0.1\r\n",
      "epoch 45, loss 0.18216, train_acc 0.9357, valid_acc 0.9008, Time 00:02:24,lr 0.1\r\n",
      "epoch 46, loss 0.17405, train_acc 0.9384, valid_acc 0.8766, Time 00:02:25,lr 0.1\r\n",
      "epoch 47, loss 0.17389, train_acc 0.9388, valid_acc 0.8975, Time 00:02:21,lr 0.1\r\n",
      "epoch 48, loss 0.17491, train_acc 0.9391, valid_acc 0.8715, Time 00:02:21,lr 0.1\r\n",
      "epoch 49, loss 0.17540, train_acc 0.9379, valid_acc 0.8709, Time 00:02:24,lr 0.1\r\n",
      "epoch 50, loss 0.17004, train_acc 0.9404, valid_acc 0.8811, Time 00:02:21,lr 0.1\r\n",
      "epoch 51, loss 0.16112, train_acc 0.9439, valid_acc 0.8539, Time 00:02:38,lr 0.1\r\n",
      "epoch 52, loss 0.17275, train_acc 0.9387, valid_acc 0.8877, Time 00:02:21,lr 0.1\r\n",
      "epoch 53, loss 0.16542, train_acc 0.9435, valid_acc 0.8326, Time 00:02:21,lr 0.1\r\n",
      "epoch 54, loss 0.16534, train_acc 0.9423, valid_acc 0.9012, Time 00:02:33,lr 0.1\r\n",
      "epoch 55, loss 0.16085, train_acc 0.9434, valid_acc 0.8797, Time 00:02:25,lr 0.1\r\n",
      "epoch 56, loss 0.16244, train_acc 0.9413, valid_acc 0.8949, Time 00:02:27,lr 0.1\r\n",
      "epoch 57, loss 0.16352, train_acc 0.9416, valid_acc 0.8826, Time 00:02:35,lr 0.1\r\n",
      "epoch 58, loss 0.15615, train_acc 0.9440, valid_acc 0.8873, Time 00:02:22,lr 0.1\r\n",
      "epoch 59, loss 0.15220, train_acc 0.9465, valid_acc 0.9070, Time 00:02:25,lr 0.1\r\n",
      "epoch 60, loss 0.15697, train_acc 0.9449, valid_acc 0.8932, Time 00:02:24,lr 0.1\r\n",
      "epoch 61, loss 0.15215, train_acc 0.9465, valid_acc 0.8229, Time 00:02:23,lr 0.1\r\n",
      "epoch 62, loss 0.15812, train_acc 0.9441, valid_acc 0.8875, Time 00:02:21,lr 0.1\r\n",
      "epoch 63, loss 0.15807, train_acc 0.9450, valid_acc 0.8920, Time 00:02:21,lr 0.1\r\n",
      "epoch 64, loss 0.15514, train_acc 0.9456, valid_acc 0.8953, Time 00:02:28,lr 0.1\r\n",
      "epoch 65, loss 0.14971, train_acc 0.9480, valid_acc 0.8965, Time 00:02:26,lr 0.1\r\n",
      "epoch 66, loss 0.14982, train_acc 0.9473, valid_acc 0.9045, Time 00:02:26,lr 0.1\r\n",
      "epoch 67, loss 0.15067, train_acc 0.9467, valid_acc 0.8861, Time 00:02:33,lr 0.1\r\n",
      "epoch 68, loss 0.14779, train_acc 0.9476, valid_acc 0.8791, Time 00:02:28,lr 0.1\r\n",
      "epoch 69, loss 0.15070, train_acc 0.9470, valid_acc 0.9002, Time 00:02:35,lr 0.1\r\n",
      "epoch 70, loss 0.14152, train_acc 0.9503, valid_acc 0.8895, Time 00:02:24,lr 0.1\r\n",
      "epoch 71, loss 0.14758, train_acc 0.9483, valid_acc 0.8871, Time 00:02:30,lr 0.1\r\n",
      "epoch 72, loss 0.14053, train_acc 0.9510, valid_acc 0.8926, Time 00:02:24,lr 0.1\r\n",
      "epoch 73, loss 0.14344, train_acc 0.9496, valid_acc 0.8816, Time 00:02:23,lr 0.1\r\n",
      "epoch 74, loss 0.14889, train_acc 0.9467, valid_acc 0.8912, Time 00:02:23,lr 0.1\r\n",
      "epoch 75, loss 0.14027, train_acc 0.9510, valid_acc 0.8465, Time 00:02:27,lr 0.1\r\n",
      "epoch 76, loss 0.13671, train_acc 0.9513, valid_acc 0.8834, Time 00:02:21,lr 0.1\r\n",
      "epoch 77, loss 0.13910, train_acc 0.9518, valid_acc 0.8566, Time 00:02:20,lr 0.1\r\n",
      "epoch 78, loss 0.13575, train_acc 0.9528, valid_acc 0.8812, Time 00:02:25,lr 0.1\r\n",
      "epoch 79, loss 0.14178, train_acc 0.9496, valid_acc 0.9014, Time 00:02:28,lr 0.1\r\n",
      "epoch 80, loss 0.13903, train_acc 0.9509, valid_acc 0.8922, Time 00:02:30,lr 0.1\r\n",
      "epoch 81, loss 0.14436, train_acc 0.9488, valid_acc 0.8992, Time 00:02:25,lr 0.1\r\n",
      "epoch 82, loss 0.13341, train_acc 0.9535, valid_acc 0.8898, Time 00:02:30,lr 0.1\r\n",
      "epoch 83, loss 0.13700, train_acc 0.9515, valid_acc 0.8869, Time 00:02:20,lr 0.1\r\n",
      "epoch 84, loss 0.13304, train_acc 0.9545, valid_acc 0.8752, Time 00:02:28,lr 0.1\r\n",
      "epoch 85, loss 0.13334, train_acc 0.9537, valid_acc 0.8602, Time 00:02:24,lr 0.1\r\n",
      "epoch 86, loss 0.13958, train_acc 0.9506, valid_acc 0.8895, Time 00:02:24,lr 0.1\r\n",
      "epoch 87, loss 0.12853, train_acc 0.9551, valid_acc 0.8781, Time 00:02:26,lr 0.1\r\n",
      "epoch 88, loss 0.13242, train_acc 0.9538, valid_acc 0.8822, Time 00:02:26,lr 0.1\r\n",
      "epoch 89, loss 0.12986, train_acc 0.9548, valid_acc 0.8924, Time 00:02:25,lr 0.1\r\n",
      "epoch 90, loss 0.08011, train_acc 0.9734, valid_acc 0.9404, Time 00:02:24,lr 0.010000000000000002\r\n",
      "epoch 91, loss 0.03974, train_acc 0.9886, valid_acc 0.9420, Time 00:02:25,lr 0.010000000000000002\r\n",
      "epoch 92, loss 0.03004, train_acc 0.9919, valid_acc 0.9465, Time 00:02:24,lr 0.010000000000000002\r\n",
      "epoch 93, loss 0.02638, train_acc 0.9928, valid_acc 0.9443, Time 00:02:23,lr 0.010000000000000002\r\n",
      "epoch 94, loss 0.02146, train_acc 0.9947, valid_acc 0.9439, Time 00:02:25,lr 0.010000000000000002\r\n",
      "epoch 95, loss 0.01932, train_acc 0.9953, valid_acc 0.9420, Time 00:02:25,lr 0.010000000000000002\r\n",
      "epoch 96, loss 0.01781, train_acc 0.9957, valid_acc 0.9436, Time 00:02:22,lr 0.010000000000000002\r\n",
      "epoch 97, loss 0.01480, train_acc 0.9968, valid_acc 0.9457, Time 00:02:21,lr 0.010000000000000002\r\n",
      "epoch 98, loss 0.01444, train_acc 0.9970, valid_acc 0.9453, Time 00:02:25,lr 0.010000000000000002\r\n",
      "epoch 99, loss 0.01331, train_acc 0.9971, valid_acc 0.9453, Time 00:02:23,lr 0.010000000000000002\r\n",
      "epoch 100, loss 0.01247, train_acc 0.9975, valid_acc 0.9480, Time 00:02:23,lr 0.010000000000000002\r\n",
      "epoch 101, loss 0.01199, train_acc 0.9973, valid_acc 0.9469, Time 00:02:22,lr 0.010000000000000002\r\n",
      "epoch 102, loss 0.01044, train_acc 0.9981, valid_acc 0.9475, Time 00:02:21,lr 0.010000000000000002\r\n",
      "epoch 103, loss 0.01006, train_acc 0.9980, valid_acc 0.9477, Time 00:02:22,lr 0.010000000000000002\r\n",
      "epoch 104, loss 0.00891, train_acc 0.9985, valid_acc 0.9482, Time 00:02:22,lr 0.010000000000000002\r\n",
      "epoch 105, loss 0.00819, train_acc 0.9986, valid_acc 0.9473, Time 00:02:25,lr 0.010000000000000002\r\n",
      "epoch 106, loss 0.00871, train_acc 0.9983, valid_acc 0.9457, Time 00:02:21,lr 0.010000000000000002\r\n",
      "epoch 107, loss 0.00809, train_acc 0.9985, valid_acc 0.9490, Time 00:02:24,lr 0.010000000000000002\r\n",
      "epoch 108, loss 0.00754, train_acc 0.9987, valid_acc 0.9486, Time 00:02:20,lr 0.010000000000000002\r\n",
      "epoch 109, loss 0.00713, train_acc 0.9987, valid_acc 0.9436, Time 00:02:23,lr 0.010000000000000002\r\n",
      "epoch 110, loss 0.00657, train_acc 0.9990, valid_acc 0.9480, Time 00:02:23,lr 0.010000000000000002\r\n",
      "epoch 111, loss 0.00636, train_acc 0.9992, valid_acc 0.9436, Time 00:02:23,lr 0.010000000000000002\r\n",
      "epoch 112, loss 0.00597, train_acc 0.9991, valid_acc 0.9465, Time 00:02:23,lr 0.010000000000000002\r\n",
      "epoch 113, loss 0.00604, train_acc 0.9990, valid_acc 0.9506, Time 00:02:25,lr 0.010000000000000002\r\n",
      "epoch 114, loss 0.00586, train_acc 0.9992, valid_acc 0.9508, Time 00:02:23,lr 0.010000000000000002\r\n",
      "epoch 115, loss 0.00560, train_acc 0.9990, valid_acc 0.9473, Time 00:02:25,lr 0.010000000000000002\r\n",
      "epoch 116, loss 0.00539, train_acc 0.9992, valid_acc 0.9420, Time 00:02:19,lr 0.010000000000000002\r\n",
      "epoch 117, loss 0.00518, train_acc 0.9993, valid_acc 0.9498, Time 00:02:22,lr 0.010000000000000002\r\n",
      "epoch 118, loss 0.00514, train_acc 0.9993, valid_acc 0.9500, Time 00:02:29,lr 0.010000000000000002\r\n",
      "epoch 119, loss 0.00482, train_acc 0.9995, valid_acc 0.9451, Time 00:02:24,lr 0.010000000000000002\r\n",
      "epoch 120, loss 0.00470, train_acc 0.9994, valid_acc 0.9459, Time 00:02:23,lr 0.010000000000000002\r\n",
      "epoch 121, loss 0.00525, train_acc 0.9992, valid_acc 0.9502, Time 00:02:20,lr 0.010000000000000002\r\n",
      "epoch 122, loss 0.00464, train_acc 0.9994, valid_acc 0.9496, Time 00:02:23,lr 0.010000000000000002\r\n",
      "epoch 123, loss 0.00449, train_acc 0.9994, valid_acc 0.9494, Time 00:02:19,lr 0.010000000000000002\r\n",
      "epoch 124, loss 0.00465, train_acc 0.9993, valid_acc 0.9484, Time 00:02:21,lr 0.010000000000000002\r\n",
      "epoch 125, loss 0.00418, train_acc 0.9994, valid_acc 0.9486, Time 00:02:23,lr 0.010000000000000002\r\n",
      "epoch 126, loss 0.00444, train_acc 0.9994, valid_acc 0.9502, Time 00:02:20,lr 0.010000000000000002\r\n",
      "epoch 127, loss 0.00413, train_acc 0.9996, valid_acc 0.9516, Time 00:02:21,lr 0.010000000000000002\r\n",
      "epoch 128, loss 0.00399, train_acc 0.9995, valid_acc 0.9467, Time 00:02:23,lr 0.010000000000000002\r\n",
      "epoch 129, loss 0.00412, train_acc 0.9995, valid_acc 0.9506, Time 00:02:28,lr 0.010000000000000002\r\n",
      "epoch 130, loss 0.00410, train_acc 0.9994, valid_acc 0.9482, Time 00:02:27,lr 0.010000000000000002\r\n",
      "epoch 131, loss 0.00384, train_acc 0.9995, valid_acc 0.9508, Time 00:02:27,lr 0.010000000000000002\r\n",
      "epoch 132, loss 0.00369, train_acc 0.9997, valid_acc 0.9506, Time 00:02:22,lr 0.010000000000000002\r\n",
      "epoch 133, loss 0.00349, train_acc 0.9996, valid_acc 0.9475, Time 00:02:25,lr 0.010000000000000002\r\n",
      "epoch 134, loss 0.00340, train_acc 0.9996, valid_acc 0.9457, Time 00:02:29,lr 0.010000000000000002\r\n",
      "epoch 135, loss 0.00348, train_acc 0.9995, valid_acc 0.9469, Time 00:02:26,lr 0.010000000000000002\r\n",
      "epoch 136, loss 0.00337, train_acc 0.9996, valid_acc 0.9475, Time 00:02:23,lr 0.010000000000000002\r\n",
      "epoch 137, loss 0.00349, train_acc 0.9995, valid_acc 0.9445, Time 00:02:29,lr 0.010000000000000002\r\n",
      "epoch 138, loss 0.00363, train_acc 0.9995, valid_acc 0.9492, Time 00:02:21,lr 0.010000000000000002\r\n",
      "epoch 139, loss 0.00314, train_acc 0.9997, valid_acc 0.9521, Time 00:02:25,lr 0.010000000000000002\r\n",
      "epoch 140, loss 0.00337, train_acc 0.9995, valid_acc 0.9453, Time 00:02:26,lr 0.0010000000000000002\r\n",
      "epoch 141, loss 0.00287, train_acc 0.9997, valid_acc 0.9488, Time 00:02:26,lr 0.0010000000000000002\r\n",
      "epoch 142, loss 0.00300, train_acc 0.9996, valid_acc 0.9512, Time 00:02:23,lr 0.0010000000000000002\r\n",
      "epoch 143, loss 0.00276, train_acc 0.9998, valid_acc 0.9516, Time 00:02:27,lr 0.0010000000000000002\r\n",
      "epoch 144, loss 0.00299, train_acc 0.9998, valid_acc 0.9506, Time 00:02:21,lr 0.0010000000000000002\r\n",
      "epoch 145, loss 0.00288, train_acc 0.9997, valid_acc 0.9516, Time 00:02:23,lr 0.0010000000000000002\r\n",
      "epoch 146, loss 0.00290, train_acc 0.9997, valid_acc 0.9521, Time 00:02:24,lr 0.0010000000000000002\r\n",
      "epoch 147, loss 0.00310, train_acc 0.9995, valid_acc 0.9508, Time 00:02:23,lr 0.0010000000000000002\r\n",
      "epoch 148, loss 0.00274, train_acc 0.9998, valid_acc 0.9525, Time 00:02:24,lr 0.0010000000000000002\r\n",
      "epoch 149, loss 0.00257, train_acc 0.9998, valid_acc 0.9510, Time 00:02:20,lr 0.0010000000000000002\r\n",
      "epoch 150, loss 0.00282, train_acc 0.9996, valid_acc 0.9502, Time 00:02:26,lr 0.0010000000000000002\r\n",
      "epoch 151, loss 0.00264, train_acc 0.9998, valid_acc 0.9453, Time 00:02:20,lr 0.0010000000000000002\r\n",
      "epoch 152, loss 0.00288, train_acc 0.9996, valid_acc 0.9512, Time 00:02:19,lr 0.0010000000000000002\r\n",
      "epoch 153, loss 0.00272, train_acc 0.9997, valid_acc 0.9506, Time 00:02:20,lr 0.0010000000000000002\r\n",
      "epoch 154, loss 0.00274, train_acc 0.9997, valid_acc 0.9514, Time 00:02:23,lr 0.0010000000000000002\r\n",
      "epoch 155, loss 0.00270, train_acc 0.9996, valid_acc 0.9506, Time 00:02:20,lr 0.0010000000000000002\r\n",
      "epoch 156, loss 0.00264, train_acc 0.9998, valid_acc 0.9527, Time 00:02:23,lr 0.0010000000000000002\r\n",
      "epoch 157, loss 0.00270, train_acc 0.9997, valid_acc 0.9518, Time 00:02:22,lr 0.0010000000000000002\r\n",
      "epoch 158, loss 0.00262, train_acc 0.9998, valid_acc 0.9520, Time 00:02:21,lr 0.0010000000000000002\r\n",
      "epoch 159, loss 0.00259, train_acc 0.9998, valid_acc 0.9508, Time 00:02:24,lr 0.0010000000000000002\r\n",
      "epoch 160, loss 0.00264, train_acc 0.9998, valid_acc 0.9518, Time 00:02:21,lr 0.0010000000000000002\r\n",
      "epoch 161, loss 0.00273, train_acc 0.9998, valid_acc 0.9516, Time 00:02:22,lr 0.0010000000000000002\r\n",
      "epoch 162, loss 0.00234, train_acc 0.9998, valid_acc 0.9486, Time 00:02:22,lr 0.0010000000000000002\r\n",
      "epoch 163, loss 0.00252, train_acc 0.9998, valid_acc 0.9486, Time 00:02:22,lr 0.0010000000000000002\r\n",
      "epoch 164, loss 0.00250, train_acc 0.9997, valid_acc 0.9516, Time 00:02:23,lr 0.0010000000000000002\r\n",
      "epoch 165, loss 0.00270, train_acc 0.9997, valid_acc 0.9510, Time 00:02:23,lr 0.0010000000000000002\r\n",
      "epoch 166, loss 0.00271, train_acc 0.9998, valid_acc 0.9492, Time 00:02:26,lr 0.0010000000000000002\r\n",
      "epoch 167, loss 0.00255, train_acc 0.9998, valid_acc 0.9514, Time 00:02:21,lr 0.0010000000000000002\r\n",
      "epoch 168, loss 0.00237, train_acc 0.9998, valid_acc 0.9512, Time 00:02:20,lr 0.0010000000000000002\r\n",
      "epoch 169, loss 0.00251, train_acc 0.9998, valid_acc 0.9527, Time 00:02:19,lr 0.0010000000000000002\r\n",
      "epoch 170, loss 0.00259, train_acc 0.9997, valid_acc 0.9482, Time 00:02:20,lr 0.0010000000000000002\r\n",
      "epoch 171, loss 0.00241, train_acc 0.9999, valid_acc 0.9518, Time 00:02:25,lr 0.0010000000000000002\r\n",
      "epoch 172, loss 0.00254, train_acc 0.9998, valid_acc 0.9463, Time 00:02:23,lr 0.0010000000000000002\r\n",
      "epoch 173, loss 0.00240, train_acc 0.9998, valid_acc 0.9518, Time 00:02:27,lr 0.0010000000000000002\r\n",
      "epoch 174, loss 0.00255, train_acc 0.9998, valid_acc 0.9479, Time 00:02:23,lr 0.0010000000000000002\r\n",
      "epoch 175, loss 0.00269, train_acc 0.9998, valid_acc 0.9518, Time 00:02:23,lr 0.0010000000000000002\r\n",
      "epoch 176, loss 0.00255, train_acc 0.9998, valid_acc 0.9516, Time 00:02:23,lr 0.0010000000000000002\r\n",
      "epoch 177, loss 0.00214, train_acc 0.9998, valid_acc 0.9475, Time 00:02:24,lr 0.0010000000000000002\r\n",
      "epoch 178, loss 0.00240, train_acc 0.9999, valid_acc 0.9486, Time 00:02:24,lr 0.0010000000000000002\r\n",
      "epoch 179, loss 0.00235, train_acc 0.9999, valid_acc 0.9529, Time 00:02:30,lr 0.0010000000000000002\r\n",
      "epoch 180, loss 0.00241, train_acc 0.9999, valid_acc 0.9510, Time 00:02:26,lr 0.0010000000000000002\r\n",
      "epoch 181, loss 0.00246, train_acc 0.9997, valid_acc 0.9447, Time 00:02:20,lr 0.0010000000000000002\r\n",
      "epoch 182, loss 0.00248, train_acc 0.9998, valid_acc 0.9520, Time 00:02:26,lr 0.0010000000000000002\r\n",
      "epoch 183, loss 0.00229, train_acc 0.9999, valid_acc 0.9508, Time 00:02:39,lr 0.0010000000000000002\r\n",
      "epoch 184, loss 0.00232, train_acc 0.9998, valid_acc 0.9510, Time 00:02:21,lr 0.0010000000000000002\r\n",
      "epoch 185, loss 0.00242, train_acc 0.9997, valid_acc 0.9510, Time 00:02:29,lr 0.0010000000000000002\r\n",
      "epoch 186, loss 0.00239, train_acc 0.9998, valid_acc 0.9516, Time 00:02:19,lr 0.0010000000000000002\r\n",
      "epoch 187, loss 0.00237, train_acc 0.9999, valid_acc 0.9490, Time 00:02:23,lr 0.0010000000000000002\r\n",
      "epoch 188, loss 0.00238, train_acc 0.9998, valid_acc 0.9518, Time 00:02:21,lr 0.0010000000000000002\r\n",
      "epoch 189, loss 0.00238, train_acc 0.9997, valid_acc 0.9486, Time 00:02:21,lr 0.0010000000000000002\r\n",
      "epoch 190, loss 0.00242, train_acc 0.9999, valid_acc 0.9475, Time 00:02:25,lr 0.0010000000000000002\r\n",
      "epoch 191, loss 0.00223, train_acc 0.9998, valid_acc 0.9463, Time 00:02:27,lr 0.0010000000000000002\r\n",
      "epoch 192, loss 0.00239, train_acc 0.9997, valid_acc 0.9506, Time 00:02:23,lr 0.0010000000000000002\r\n",
      "epoch 193, loss 0.00230, train_acc 0.9998, valid_acc 0.9504, Time 00:02:27,lr 0.0010000000000000002\r\n",
      "epoch 194, loss 0.00220, train_acc 0.9999, valid_acc 0.9520, Time 00:02:20,lr 0.0010000000000000002\r\n",
      "epoch 195, loss 0.00247, train_acc 0.9997, valid_acc 0.9525, Time 00:02:37,lr 0.0010000000000000002\r\n",
      "epoch 196, loss 0.00248, train_acc 0.9997, valid_acc 0.9488, Time 00:02:32,lr 0.0010000000000000002\r\n",
      "epoch 197, loss 0.00252, train_acc 0.9997, valid_acc 0.9516, Time 00:02:27,lr 0.0010000000000000002\r\n",
      "epoch 198, loss 0.00252, train_acc 0.9996, valid_acc 0.9518, Time 00:02:26,lr 0.0010000000000000002\r\n",
      "epoch 199, loss 0.00207, train_acc 0.9999, valid_acc 0.9469, Time 00:02:25,lr 0.0010000000000000002\r\n",
      "/home/dske/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/block.py:462: UserWarning: save_params is deprecated. Please use save_parameters. Note that if you want load from SymbolBlock later, please use export instead. For details, see https://mxnet.apache.org/tutorials/gluon/save_load_params.html\r\n",
      "  warnings.warn(\"save_params is deprecated. Please use save_parameters. \"\r\n",
      "/home/dske/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/block.py:462: UserWarning: save_params is deprecated. Please use save_parameters. Note that if you want load from SymbolBlock later, please use export instead. For details, see https://mxnet.apache.org/tutorials/gluon/save_load_params.html\r\n",
      "  warnings.warn(\"save_params is deprecated. Please use save_parameters. \"\r\n",
      "/home/dske/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/block.py:462: UserWarning: save_params is deprecated. Please use save_parameters. Note that if you want load from SymbolBlock later, please use export instead. For details, see https://mxnet.apache.org/tutorials/gluon/save_load_params.html\r\n",
      "  warnings.warn(\"save_params is deprecated. Please use save_parameters. \"\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"CIFAR10_train-Copy1.py\", line 421, in <module>\r\n",
      "    res164__2_e255_focal_clip_all_data\r\n",
      "NameError: name 'res164__2_e255_focal_clip_all_data' is not defined\r\n"
     ]
    }
   ],
   "source": [
    "!cat /home/dske/lx/workspace/CIFAR10_mxnet/CIFAR10_train.log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readme.md\t\t\t    resnet164_e300\r\n",
      "res164__2_e255_focal_clip_all_data  shelock_densenet_orign\r\n",
      "resnet164_e0-255_focal_clip\t    shelock_resnet_orign\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/dske/lx/workspace/CIFAR10_mxnet/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
