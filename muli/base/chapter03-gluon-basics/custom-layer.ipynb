{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设计自定义层 \n",
    "我看先来看如何定义一个简单层，它不需要维护模型参数。事实上这个跟前面介绍的如何使用nn.Block没什么区别。下面代码定义一个层将减掉均值 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd \n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CenteredLayer(nn.Block):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(CenteredLayer,self).__init__(**kwargs)\n",
    "    \n",
    "    def forward(self,x): \n",
    "        return x-x.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以马上实例化这个层用起来 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[-2. -1.  0.  1.  2.]\n",
       "<NDArray 5 @cpu(0)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer=CenteredLayer() \n",
    "layer(nd.array([1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以用它来构造更复杂的神经网络 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(nn.Dense(128))\n",
    "    net.add(nn.Dense(10))\n",
    "    net.add(CenteredLayer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确认下输出的均值确实是0: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[-4.25069369e-02  2.76193079e-02  5.38392551e-02 -8.66032206e-05\n",
      "  -4.78977449e-02 -1.96425803e-02  2.09131949e-02  6.18448434e-03\n",
      "   3.31263221e-03 -2.44515762e-02]\n",
      " [-2.72416081e-02  5.39518101e-03  3.93499807e-02 -1.81009434e-02\n",
      "  -2.04518754e-02 -2.84789596e-03  1.41671039e-02  2.61938758e-02\n",
      "   2.30672173e-02 -3.95172043e-03]\n",
      " [-2.57457346e-02  3.63405645e-02  6.61725551e-02 -4.23212675e-03\n",
      "  -4.59269471e-02 -3.13036293e-02  1.17697865e-02 -2.39959452e-03\n",
      "   2.08159257e-02 -1.89681370e-02]\n",
      " [-1.96682289e-02  1.73189603e-02  1.62064843e-02 -6.78200973e-03\n",
      "  -2.63251383e-02 -1.18263029e-02  1.67988148e-03  2.64359247e-02\n",
      "  -9.39494930e-03 -7.03005167e-03]]\n",
      "<NDArray 4x10 @cpu(0)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[-6.635673e-10]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize() \n",
    "y=net(nd.random.uniform(shape=(4,8))) \n",
    "print(y)\n",
    "y.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然大部分情况你可以看不到一个实实在在的0，而是一个很小的数。例如：5.645646356e-11。\n",
    "这是因为 MXNet默认使用 32位float，会带来一定的浮点精度误差 \n",
    "\n",
    "# 带模型参数的自定义层 \n",
    "虽然Centeredlayer 可能会告诉实现自定义层大概是什么样子，但它缺少了最重要的一环，就是它没有可以学习的模型参数 \n",
    "\n",
    "记得我们之前访问Dense 的权重的时候是通过dense.weight.data() ,这里的weight 是一个 Parameter 的类型。我们可以显示的构建这样一个参数。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "my_param=gluon.Parameter('exciting_parameter_yay',shape=(3,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [[-0.02548236  0.05326662 -0.01200318]\n",
       "  [ 0.05855297 -0.06101935 -0.0396449 ]\n",
       "  [ 0.0269461   0.00912645  0.0093242 ]]\n",
       " <NDArray 3x3 @cpu(0)>,\n",
       " \n",
       " [[0. 0. 0.]\n",
       "  [0. 0. 0.]\n",
       "  [0. 0. 0.]]\n",
       " <NDArray 3x3 @cpu(0)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_param.initialize() \n",
    "(my_param.data(),my_param.grad())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常自定义层的时候我们不会直接创建 Parameter ,而是通过BLOCK自带的一个ParameterDict 类型的成员变量\n",
    "params,顾名思义，这是一个由字符串名字映射到Paramete的字典 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "block_ (\n",
       "  Parameter block_exciting_parameter_yay (shape=(3, 3), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd=gluon.ParameterDict(prefix='block_') \n",
    "pd.get('exciting_parameter_yay',shape=(3,3)) \n",
    "pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们看下如果实现一个跟Dense 一样功能的层，它概念跟前面的CenteredLayer 的主要区别\n",
    "是我们在初始函数里通过Params创建了参数： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(nn.Block):\n",
    "    def __init__(self,units,in_units,**kwargs):\n",
    "        super(MyDense,self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.weight=self.params.get(\n",
    "            'weight',shape=(in_units,units))\n",
    "            self.bias=self.params.get('bias',shape=(units,)) \n",
    "    def forward(self,x):\n",
    "        linear=nd.dot(x,self.weight.data())+self.bias.data()\n",
    "        return nd.relu(linear) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们创建实例化一个对象来看下它的参数，这里我们特意加了前缀prefix,这是nn.Block初始化函数自带的参数。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "o_my_dense_ (\n",
       "  Parameter o_my_dense_weight (shape=(10, 5), dtype=<class 'numpy.float32'>)\n",
       "  Parameter o_my_dense_bias (shape=(5,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense=MyDense(5,in_units=10,prefix='o_my_dense_') \n",
    "dense.params "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它的使用跟前面没有什么不一致："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.         0.         0.0301928  0.09594411 0.13613266]\n",
       " [0.         0.         0.00460232 0.10275271 0.15692513]]\n",
       "<NDArray 2x5 @cpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.initialize() \n",
    "dense(nd.random.uniform(shape=(2,10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们构造的层跟Gluon 提供的层用起来没太多区别： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.         0.06250843]\n",
       " [0.00077506 0.08170694]]\n",
       "<NDArray 2x2 @cpu(0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=nn.Sequential() \n",
    "with net.name_scope():\n",
    "    net.add(MyDense(32,in_units=64))\n",
    "    net.add(MyDense(2,in_units=32))\n",
    "net.initialize() \n",
    "net(nd.random.uniform(shape=(2,64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 29 22:07:41 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 27%   25C    P8    19W / 250W |   1401MiB / 11016MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1814      G   /usr/lib/xorg/Xorg                 14MiB |\n",
      "|    0   N/A  N/A      1902      G   /usr/bin/gnome-shell               57MiB |\n",
      "|    0   N/A  N/A      2483      G   /usr/lib/xorg/Xorg                 91MiB |\n",
      "|    0   N/A  N/A      2624      G   /usr/bin/gnome-shell              155MiB |\n",
      "|    0   N/A  N/A      3384      G   ...mviewer/tv_bin/TeamViewer       22MiB |\n",
      "|    0   N/A  N/A     25813      C   ...da3/envs/gluon/bin/python     1053MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
