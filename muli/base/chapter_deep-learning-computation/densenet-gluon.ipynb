{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到DenseNet 里来自跳层的输出不是通过加法（+）而是拼接（concat) l来跟目前层的输出合并。因为是拼接，所以底层的输出会保留的进入上面的所有层。这是为什么叫做“稠密连接\" 的原因 。\n",
    "# 稠密块 （Dense Block) \n",
    "我们来定义一个稠密连接块。 DenseNet的卷积块使用ResNet改进版本的BN->Relu->Conv。每个卷积的输出通道数被称为growth_rate,这是因为假设输出为in_channels,而且有layers 层，那么输出的通道数就是in_channels+groth_rate+layers。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd \n",
    "from mxnet.gluon import nn \n",
    "def conv_block(channels):\n",
    "    out=nn.Sequential()\n",
    "    out.add(\n",
    "        nn.BatchNorm(),\n",
    "        nn.Activation('relu'),\n",
    "        nn.Conv2D(channels,kernel_size=3,padding=1) \n",
    "    )\n",
    "    return out \n",
    "\n",
    "class DenseBlock(nn.Block):\n",
    "    def __init__(self,layers,growth_rate,**kwargs):\n",
    "        super(DenseBlock,self).__init__(**kwargs)\n",
    "        self.net=nn.Sequential()\n",
    "        for i in range(layers):\n",
    "            self.net.add(conv_block(growth_rate)) \n",
    "    def forward(self,X):\n",
    "        for layer in self.net:\n",
    "            out=layer(X)\n",
    "            X=nd.concat(X,out,dim=1) \n",
    "        return X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们验证下输出通道数是不是符合预期 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 36, 8, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dblk=DenseBlock(3,11) \n",
    "dblk.initialize() \n",
    "\n",
    "x=nd.random.uniform(shape=(4,3,8,8)) \n",
    "dblk(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 过度块（Transition Block) \n",
    "因为使用拼接的缘故，没经过一次过渡块输出通道数可能会激增。为了控制模型复杂度，这里引入一个过渡块，它不仅把输入的长度减半，同事也使用1X1卷积来改变通道数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(channels):\n",
    "    out=nn.Sequential() \n",
    "    out.add(\n",
    "        nn.BatchNorm(),\n",
    "        nn.Activation('relu'),\n",
    "        nn.Conv2D(channels,kernel_size=1) ,\n",
    "        nn.AvgPool2D(pool_size=2,strides=2) \n",
    "    )\n",
    "    return out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证一下结果 ： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10, 4, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tblk=transition_block(10) \n",
    "tblk.initialize() \n",
    "tblk(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet \n",
    "DenseNet 的主体就是交替串联稠密块和过渡块。它使用全局的growth_rate来使得配置更加简单。过渡层每次都会将通道数减半。\n",
    "下面定义一个121层的DenseNet。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_channels=64\n",
    "growth_rate=32\n",
    "block_layers=[6,12,24,16]\n",
    "num_classes=10 \n",
    "\n",
    "\n",
    "def dense_net():\n",
    "    net=nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        # first block \n",
    "        net.add(\n",
    "            nn.Conv2D(init_channels,\n",
    "                      kernel_size=7,strides=2,padding=3),\n",
    "            nn.BatchNorm(),\n",
    "            nn.Activation('relu') ,\n",
    "            nn.MaxPool2D(pool_size=3,strides=2,padding=1) \n",
    "        )\n",
    "        # dense blocks \n",
    "        channels=init_channels \n",
    "        for i,layers in enumerate(block_layers):\n",
    "            net.add(DenseBlock(layers,growth_rate)) \n",
    "            channels+=layers* growth_rate \n",
    "            if i!=len(block_layers)-1:\n",
    "        \n",
    "        # last block \n",
    "        net.add( \n",
    "            nn.BatchNorm(),\n",
    "            nn.Activation('relu'),\n",
    "            nn.AvgPool2D(pool_size=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dense(num_classes) \n",
    "        )\n",
    "    return net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
