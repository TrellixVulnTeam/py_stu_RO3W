{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn \n",
    "from mxnet import nd \n",
    "class Inception(nn.Block):\n",
    "    def __init__(self,c1,c2,c3,c4,**kwargs):\n",
    "        super(Inception,self).__init__(**kwargs)\n",
    "        # 线路1，单1 x 1卷积层\n",
    "        self.p1_1 = nn.Conv2D(c1, kernel_size=1, activation='relu')\n",
    "        # 线路2，1 x 1卷积层后接3 x 3卷积层\n",
    "        self.p2_1 = nn.Conv2D(c2[0], kernel_size=1, activation='relu')\n",
    "        self.p2_2 = nn.Conv2D(c2[1], kernel_size=3, padding=1,\n",
    "                              activation='relu')\n",
    "        # 线路3，1 x 1卷积层后接5 x 5卷积层\n",
    "        self.p3_1 = nn.Conv2D(c3[0], kernel_size=1, activation='relu')\n",
    "        self.p3_2 = nn.Conv2D(c3[1], kernel_size=5, padding=2,\n",
    "                              activation='relu')\n",
    "        # 线路4，3 x 3最大池化层后接1 x 1卷积层\n",
    "        self.p4_1 = nn.MaxPool2D(pool_size=3, strides=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2D(c4, kernel_size=1, activation='relu')\n",
    " \n",
    "    def forward(self, x):\n",
    "        p1 = self.p1_1(x)\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        return nd.concat(p1, p2, p3, p4, dim=1)  # 在通道维上连结输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到Inception里面有4个并行的线路.\n",
    "1. 单个 1 * 1 卷积 。 \n",
    "2. 1 * 1 卷积接上3 * 3卷积。通常前者的通道数少于输入通道，这样减少后者的计算量。后者加上了padding=1 使得输出的长宽的输入一致 \n",
    "3.同2，但换成了5 * 5 卷积\n",
    "4.和1类似，但卷积前用了最大池化层 \n",
    "最后将这四个并行线路的结果在通道这个纬度上合并在一起。\n",
    "测试一下： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incp=Inception(64,96,128,16,32,32) \n",
    "# incp.initialize() \n",
    "# x=nd.random.uniform(shape=(32,3,64,64)) \n",
    "# incp(x).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Block):\n",
    "    def __init__(self,num_classes,verbose=False,**kwargs):\n",
    "        super(GoogLeNet,self).__init__(**kwargs)\n",
    "        self.verbose=verbose\n",
    "        with self.name_scope():\n",
    "            # block 1 \n",
    "            b1 = nn.Sequential()\n",
    "            b1.add(nn.Conv2D(64, kernel_size=7, strides=2, padding=3, \n",
    "                             activation='relu'),\n",
    "                   nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "            #block 2 \n",
    "            b2 = nn.Sequential()\n",
    "            b2.add(nn.Conv2D(64, kernel_size=1, activation='relu'),\n",
    "               nn.Conv2D(192, kernel_size=3, padding=1, activation='relu'),\n",
    "                nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "            #block3 \n",
    "            b3 = nn.Sequential()\n",
    "            b3.add(Inception(64, (96, 128), (16, 32), 32),\n",
    "                   Inception(128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "            # block 4 \n",
    "            b4 = nn.Sequential()\n",
    "            b4.add(Inception(192, (96, 208), (16, 48), 64),\n",
    "                   Inception(160, (112, 224), (24, 64), 64),\n",
    "                   Inception(128, (128, 256), (24, 64), 64),\n",
    "                   Inception(112, (144, 288), (32, 64), 64),\n",
    "                   Inception(256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2D(pool_size=3, strides=2, padding=1))            \n",
    "            #block 5 \n",
    "            b5 = nn.Sequential()\n",
    "            b5.add(Inception(256, (160, 320), (32, 128), 128),\n",
    "                   Inception(384, (192, 384), (48, 128), 128),\n",
    "                    nn.AvgPool2D(pool_size=2))\n",
    "#                    nn.GlobalAvgPool2D())\n",
    "            # block 6 \n",
    "            b6=nn.Sequential()\n",
    "            b6.add(\n",
    "                nn.Flatten(),\n",
    "                nn.Dense(num_classes) \n",
    "            )\n",
    "            # chain blocks together \n",
    "            self.net=nn.Sequential()\n",
    "            self.net.add(b1,b2,b3,b4,b5,b6)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=x\n",
    "        for i,b in enumerate(self.net):\n",
    "            out=b(out) \n",
    "            if self.verbose:\n",
    "                print(\"Block %d output: %s \"%(i+1,out.shape))\n",
    "        return out\n",
    "    \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看一下每个快对输出的改变 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1 output: (4, 64, 24, 24) \n",
      "Block 2 output: (4, 192, 12, 12) \n",
      "Block 3 output: (4, 480, 6, 6) \n",
      "Block 4 output: (4, 832, 3, 3) \n",
      "Block 5 output: (4, 1024, 1, 1) \n",
      "Block 6 output: (4, 10) \n"
     ]
    }
   ],
   "source": [
    "net=GoogLeNet(10,verbose=True) \n",
    "net.initialize() \n",
    "x=nd.random.uniform(shape=(4,3,96,96))\n",
    "y=net(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跟VGG一样我们使用了较小的输入96 * 96来加速计算 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaa\n",
      "Start training on  gpu(0)\n",
      "Epoch 0. Loss: 2.264, Train acc 0.26, Test acc 0.30, Time 73.1 sec\n",
      "time is : 73.074108\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('..') \n",
    "import utils \n",
    "from mxnet import gluon\n",
    "from mxnet import init \n",
    "import time \n",
    "train_data,test_data=utils.load_data_fashion_mnist(\n",
    "            batch_size=64,resize=96) \n",
    "ctx=utils.try_gpu() \n",
    "net=GoogLeNet(10) \n",
    "net.initialize(ctx=ctx,init=init.Xavier()) \n",
    "loss=gluon.loss.SoftmaxCrossEntropyLoss() \n",
    "trainer=gluon.Trainer(net.collect_params(),'sgd',{'learning_rate':0.01})\n",
    "start=time.time()\n",
    "utils.train(train_data,test_data,net,loss,trainer,ctx,num_epochs=1) \n",
    "end=time.time()\n",
    "print(\"time is : %f\"%(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结论 \n",
    "googLeNet 加入了更加结构化的Inception快来使我们可以使用更大的通道，更多的层，同事控制计算量和模型大小在合理范围内 \n",
    "\n",
    "# 练习 \n",
    "GoogLeNet 有数个后续的版本，尝试实现他们并运行看看有什么不一样 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
