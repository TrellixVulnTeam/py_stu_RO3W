{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "net=nn.Sequential()\n",
    "with net.name_scope():\n",
    "    # 第一阶段 \n",
    "    net.add(nn.Conv2D( channels=224,kernel_size=11,strides=4,activation='relu'))\n",
    "    net.add(nn.MaxPool2D(pool_size=3,strides=2))\n",
    "    # 第二阶段 \n",
    "    net.add(nn.Conv2D(\n",
    "        channels=256,kernel_size=5,padding=2,activation='relu'))\n",
    "    net.add(nn.MaxPool2D(pool_size=3,strides=2))\n",
    "    #第三阶段 \n",
    "    net.add(nn.Conv2D(\n",
    "                channels=384,kernel_size=3,padding=1,activation='relu'))\n",
    "    \n",
    "    net.add(nn.Conv2D(channels=384,kernel_size=3,padding=1,activation='relu'))\n",
    "    \n",
    "    net.add(nn.Conv2D(channels=256,kernel_size=3,padding=1,activation='relu'))\n",
    "    net.add(nn.MaxPool2D(pool_size=3,strides=2)) \n",
    "    # 第四阶段 \n",
    "    net.add(nn.Flatten())\n",
    "    net.add(nn.Dense(4096,activation='relu'))\n",
    "    net.add(nn.Dropout(.5))\n",
    "    #第五阶段 \n",
    "    net.add(nn.Dense(4096,activation='relu'))\n",
    "    net.add(nn.Dropout(.5))\n",
    "    # 第六阶段 \n",
    "    net.add(nn.Dense(10))\n",
    "     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据 \n",
    "Alexnet 使用的Imagenet数据，其中输入图片大小一般是 224*224。因为imageNet数据训练时间过长，我们用FashionMNIST\n",
    "来演示。这里我们额外做了一步将数据扩大到224*224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') \n",
    "import utils\n",
    "from mxnet import image\n",
    "\n",
    "def transform(data,label):\n",
    "    data=image.imresize(data,224,224) \n",
    "    return utils.transform_mnist(data,label) \n",
    "batch_size=64 \n",
    "train_data,test_data=utils.load_data_fashion_mnist(batch_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练 \n",
    "这时候我们可以开始训练。相对于前面的LeNet，我们做了如下三个改动：\n",
    "\n",
    "1. 我们使用Xavier来初始化参数 \n",
    "2. 使用了更小的学习率\n",
    "3. 默认只迭代一轮（这样网页编译快点一点 ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "b'[21:53:39] /opt/concourse/worker/volumes/live/e490c994-58a7-4435-729f-6d8cf3f66ffa/volume/libmxnet_1564766672285/work/src/operator/nn/pooling.cc:190: Check failed: param.kernel[0] <= dshape_nchw[2] + 2 * param.pad[0]: kernel size (3) exceeds input (2 padded to 2)\\nStack trace:\\n  [bt] (0) 1   libmxnet.dylib                      0x000000011186ddd9 dmlc::LogMessageFatal::~LogMessageFatal() + 57\\n  [bt] (1) 2   libmxnet.dylib                      0x000000011210f12a mxnet::op::PoolingShape(nnvm::NodeAttrs const&, std::__1::vector<mxnet::TShape, std::__1::allocator<mxnet::TShape> >*, std::__1::vector<mxnet::TShape, std::__1::allocator<mxnet::TShape> >*) + 3978\\n  [bt] (2) 3   libmxnet.dylib                      0x00000001119ecc87 mxnet::imperative::SetShapeType(mxnet::Context const&, nnvm::NodeAttrs const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, mxnet::DispatchMode*) + 1783\\n  [bt] (3) 4   libmxnet.dylib                      0x00000001119eb380 mxnet::Imperative::Invoke(mxnet::Context const&, nnvm::NodeAttrs const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&) + 720\\n  [bt] (4) 5   libmxnet.dylib                      0x00000001118a06a2 MXImperativeInvokeImpl(void*, int, void**, int*, void***, int, char const**, char const**) + 386\\n  [bt] (5) 6   libmxnet.dylib                      0x00000001118a181e MXImperativeInvokeEx + 190\\n  [bt] (6) 7   ndarray.cpython-36m-darwin.so       0x0000000110b4de48 __pyx_pw_5mxnet_4_cy3_7ndarray_3_imperative_invoke(_object*, _object*, _object*) + 4600\\n  [bt] (7) 8   python                              0x0000000100d22ac0 _PyCFunction_FastCallDict + 400\\n  [bt] (8) 9   python                              0x0000000100dee20a call_function + 154\\n\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2bb478feb79a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msoftmax_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/nn/basic_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/nn/conv_layers.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, x)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fwd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36mPooling\u001b[0;34m(data, kernel, pool_type, global_pool, cudnn_off, pooling_convention, stride, pad, p_value, count_include_pad, layout, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32mmxnet/cython/ndarray.pyx\u001b[0m in \u001b[0;36mmxnet._cy3.ndarray._imperative_invoke\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/mxnet/_cy3/ndarray.cpython-36m-darwin.so\u001b[0m in \u001b[0;36mmxnet._cy3.ndarray.CALL\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: b'[21:53:39] /opt/concourse/worker/volumes/live/e490c994-58a7-4435-729f-6d8cf3f66ffa/volume/libmxnet_1564766672285/work/src/operator/nn/pooling.cc:190: Check failed: param.kernel[0] <= dshape_nchw[2] + 2 * param.pad[0]: kernel size (3) exceeds input (2 padded to 2)\\nStack trace:\\n  [bt] (0) 1   libmxnet.dylib                      0x000000011186ddd9 dmlc::LogMessageFatal::~LogMessageFatal() + 57\\n  [bt] (1) 2   libmxnet.dylib                      0x000000011210f12a mxnet::op::PoolingShape(nnvm::NodeAttrs const&, std::__1::vector<mxnet::TShape, std::__1::allocator<mxnet::TShape> >*, std::__1::vector<mxnet::TShape, std::__1::allocator<mxnet::TShape> >*) + 3978\\n  [bt] (2) 3   libmxnet.dylib                      0x00000001119ecc87 mxnet::imperative::SetShapeType(mxnet::Context const&, nnvm::NodeAttrs const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, mxnet::DispatchMode*) + 1783\\n  [bt] (3) 4   libmxnet.dylib                      0x00000001119eb380 mxnet::Imperative::Invoke(mxnet::Context const&, nnvm::NodeAttrs const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&) + 720\\n  [bt] (4) 5   libmxnet.dylib                      0x00000001118a06a2 MXImperativeInvokeImpl(void*, int, void**, int*, void***, int, char const**, char const**) + 386\\n  [bt] (5) 6   libmxnet.dylib                      0x00000001118a181e MXImperativeInvokeEx + 190\\n  [bt] (6) 7   ndarray.cpython-36m-darwin.so       0x0000000110b4de48 __pyx_pw_5mxnet_4_cy3_7ndarray_3_imperative_invoke(_object*, _object*, _object*) + 4600\\n  [bt] (7) 8   python                              0x0000000100d22ac0 _PyCFunction_FastCallDict + 400\\n  [bt] (8) 9   python                              0x0000000100dee20a call_function + 154\\n\\n'"
     ]
    }
   ],
   "source": [
    "from mxnet import autograd \n",
    "from mxnet import gluon \n",
    "from mxnet import nd \n",
    "from mxnet import init \n",
    "ctx=utils.try_gpu()\n",
    "\n",
    "net.initialize(ctx=ctx,init=init.Xavier())\n",
    "softmax_cross_entropy=gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer=gluon.Trainer(\n",
    "    net.collect_params(),'sgd',{'learning_rate':0.01})\n",
    "for epoch in range(1):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0. \n",
    "    for data, label in train_data:\n",
    "        label=label.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output=net(data.as_in_context(ctx ))\n",
    "            loss=softmax_cross_entropy(output,label)\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size) \n",
    "        train_loss+=nd.mean(loss).asscalar() \n",
    "        train_acc+=utils.accuracy(output,label)\n",
    "    test_acc=utils.evaluate_accuracy(test_data,net,ctx) \n",
    "    print(\"Epoch %d . loss :%f ,train acc %f,Test acc%f \"% \n",
    "          (epoch,train_loss/len(train_data),train_acc.asscalar()/len(train_data),test_acc)\n",
    "          ) \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
