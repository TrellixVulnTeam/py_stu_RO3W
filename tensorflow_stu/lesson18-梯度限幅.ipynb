{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "living-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import datasets,layers,optimizers \n",
    "import os \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "(x,y),_=datasets.mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regional-creator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (60000, 28, 28) ;y: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x,y),_=datasets.mnist.load_data()\n",
    "x=tf.convert_to_tensor(x,dtype=tf.float32)/50.0 \n",
    "y=tf.convert_to_tensor(y) \n",
    "y=tf.one_hot(y,depth=10) \n",
    "print('x:',x.shape,';y:',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "figured-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db=tf.data.Dataset.from_tensor_slices((x,y)).batch(128).repeat(30) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cathedral-durham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensorflow.python.data.ops.dataset_ops.RepeatDataset, 14070)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_db),len(train_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "saved-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(iter(train_db)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "unknown-spectacular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: (128, 28, 28) (128, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"sample:\",x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 , loss: 0.4792906641960144\n",
      "199 , loss: 0.1569278985261917\n",
      "299 , loss: 0.11318264901638031\n",
      "399 , loss: 0.08691087365150452\n",
      "499 , loss: 0.08155898004770279\n",
      "599 , loss: 0.08343525230884552\n",
      "699 , loss: 0.06265544891357422\n",
      "799 , loss: 0.08769796043634415\n",
      "899 , loss: 0.059297334402799606\n",
      "999 , loss: 0.06494517624378204\n",
      "1099 , loss: 0.05724070221185684\n",
      "1199 , loss: 0.06060907244682312\n",
      "1299 , loss: 0.06548172235488892\n",
      "1399 , loss: 0.04827360436320305\n",
      "1499 , loss: 0.05478452518582344\n",
      "1599 , loss: 0.05993899703025818\n",
      "1699 , loss: 0.05511237308382988\n",
      "1799 , loss: 0.053787607699632645\n",
      "1899 , loss: 0.05151485279202461\n",
      "1999 , loss: 0.0632849782705307\n",
      "2099 , loss: 0.05157947540283203\n",
      "2199 , loss: 0.06049016863107681\n",
      "2299 , loss: 0.046931587159633636\n",
      "2399 , loss: 0.04994022846221924\n",
      "2499 , loss: 0.041960012167692184\n",
      "2599 , loss: 0.04982219263911247\n",
      "2699 , loss: 0.04603290930390358\n",
      "2799 , loss: 0.0373048409819603\n",
      "2899 , loss: 0.04170092195272446\n",
      "2999 , loss: 0.046118784695863724\n",
      "3099 , loss: 0.04522048681974411\n",
      "3199 , loss: 0.03446463495492935\n",
      "3299 , loss: 0.034254442900419235\n",
      "3399 , loss: 0.03565605729818344\n",
      "3499 , loss: 0.042401500046253204\n",
      "3599 , loss: 0.04404754191637039\n",
      "3699 , loss: 0.03424305468797684\n",
      "3799 , loss: 0.029829049482941628\n",
      "3899 , loss: 0.03488346189260483\n",
      "3999 , loss: 0.04831258952617645\n",
      "4099 , loss: 0.035372983664274216\n",
      "4199 , loss: 0.04236096888780594\n",
      "4299 , loss: 0.035120077431201935\n",
      "4399 , loss: 0.03463924303650856\n",
      "4499 , loss: 0.039028801023960114\n",
      "4599 , loss: 0.030374545603990555\n",
      "4699 , loss: 0.03466443717479706\n",
      "4799 , loss: 0.04299038648605347\n",
      "4899 , loss: 0.03514537960290909\n",
      "4999 , loss: 0.03324662894010544\n",
      "5099 , loss: 0.028818314895033836\n",
      "5199 , loss: 0.03339148685336113\n",
      "5299 , loss: 0.03063376620411873\n",
      "5399 , loss: 0.037526845932006836\n",
      "5499 , loss: 0.02913503907620907\n",
      "5599 , loss: 0.02915983460843563\n",
      "5699 , loss: 0.030416792258620262\n",
      "5799 , loss: 0.02928057312965393\n",
      "5899 , loss: 0.03611677139997482\n",
      "5999 , loss: 0.03634984418749809\n",
      "6099 , loss: 0.02539253607392311\n",
      "6199 , loss: 0.03746163100004196\n",
      "6299 , loss: 0.029385844245553017\n",
      "6399 , loss: 0.02686985954642296\n",
      "6499 , loss: 0.026147086173295975\n",
      "6599 , loss: 0.02946343459188938\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    w1,b1=tf.Variable(tf.random.truncated_normal([784,512],stddev=0.1)),tf.Variable(tf.random.truncated_normal([512],stddev=0.1))\n",
    "    w2,b2=tf.Variable(tf.random.truncated_normal([512,256],stddev=0.1)),tf.Variable(tf.random.truncated_normal([256],stddev=0.1))\n",
    "    w3,b3=tf.Variable(tf.random.truncated_normal([256,10],stddev=0.1)),tf.Variable(tf.random.truncated_normal([10],stddev=0.1))\n",
    "    optimizer=optimizers.SGD(lr=0.01)\n",
    "    for step,(x,y) in enumerate(train_db):\n",
    "        x=tf.reshape(x,(-1,784)) \n",
    "        with tf.GradientTape() as tape:\n",
    "            #layer1\n",
    "            h1=x@w1+b1\n",
    "            h1=tf.nn.relu(h1) \n",
    "            #layer2 \n",
    "            h2=h1@w2+b2\n",
    "            h2=tf.nn.relu(h2) \n",
    "            #output\n",
    "            out=h2@w3+b3 \n",
    "            loss=tf.square(y-out) \n",
    "            loss=tf.reduce_mean(loss)\n",
    "        \n",
    "#         print('=== before === ')\n",
    "        grads=tape.gradient(loss,[w1,b1,w2,b2,w3,b3])\n",
    "        \n",
    "#         for g in grads:\n",
    "#             print(tf.norm(g)) \n",
    "        grads,_=tf.clip_by_global_norm(grads,15) \n",
    "#         print('=== after === ')\n",
    "#         for g in grads:\n",
    "#             print(tf.norm(g)) \n",
    "        optimizer.apply_gradients(zip(grads,[w1,b1,w2,b2,w3,b3]))\n",
    "        if (step+1)%100==0:\n",
    "            print(step,', loss:',float(loss))\n",
    "    for step,(x,y) in enumerate(test_db):\n",
    "        \n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-boundary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
