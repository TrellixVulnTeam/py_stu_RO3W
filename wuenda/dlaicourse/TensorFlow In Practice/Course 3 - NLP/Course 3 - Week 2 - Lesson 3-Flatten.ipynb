{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eastern-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "relevant-mistress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "discrete-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow-datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unlikely-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds \n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.2)\n",
    "config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "imdb,info=tfds.load('imdb_reviews/subwords8k',with_info=True,as_supervised=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "numerical-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1,test_data1=imdb['train'],imdb['test'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "foreign-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=info.features['text'].encoder \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "talented-polymer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [6307, 2327, 4043, 2120, 2, 48, 2715, 7, 2652, 8050]\n"
     ]
    }
   ],
   "source": [
    "sample_string='TensorFlow, from basic to mastery'\n",
    "tokenized_string =tokenizer.encode(sample_string) \n",
    "print('Tokenized string is {}'.format(tokenized_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "severe-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original string : TensorFlow, from basic to mastery\n"
     ]
    }
   ],
   "source": [
    "original_string=tokenizer.decode(tokenized_string) \n",
    "print('The original string : {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moved-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6307 ----->Ten\n",
      "2327 ----->sor\n",
      "4043 ----->Fl\n",
      "2120 ----->ow\n",
      "2 ----->, \n",
      "48 ----->from \n",
      "2715 ----->basic \n",
      "7 ----->to \n",
      "2652 ----->master\n",
      "8050 ----->y\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print('{} ----->{}'.format(ts,tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "every-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "max_length = 120\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(tokenizer.vocab_size, embedding_dim),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.vocab_size*embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "# train_data = train_data1.map(lambda x_text, x_label: (x_text, tf.expand_dims(x_label, -1)),num_parallel_calls=4)\n",
    "# test_data = test_data1.map(lambda x_text, x_label: (x_text, tf.expand_dims(x_label, -1)),num_parallel_calls=4)\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_data1 = train_data1.shuffle(BUFFER_SIZE)\n",
    "train_data = train_data1.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(train_data1))\n",
    "test_data= test_data1.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(test_data1))\n",
    "\n",
    "history = model.fit(train_data, epochs=num_epochs, validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "def plot_graphs(history,string):\n",
    "    plt.plot(history.history[string]) \n",
    "    plt.plot(history.history['val_'+string]) \n",
    "    plt.xlabel('Epochs') \n",
    "    plt.ylabel(string) \n",
    "    plt.legend([string,'val_'+string]) \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in train_data:\n",
    "    print(a) \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-rates",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
