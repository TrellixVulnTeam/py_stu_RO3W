{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dske/anaconda3/envs/gluon/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/dske/anaconda3/envs/gluon/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/dske/anaconda3/envs/gluon/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/dske/anaconda3/envs/gluon/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/dske/anaconda3/envs/gluon/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/dske/anaconda3/envs/gluon/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 16s 261us/step - loss: 0.4337 - acc: 0.8433\n",
      "Epoch 2/5\n",
      "35936/60000 [================>.............] - ETA: 5s - loss: 0.3006 - acc: 0.8901"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7fbc635c1a2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gluon/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/gluon/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    219\u001b[0m           \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gluon/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    249\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     if (self._delta_t_batch > 0. and\n\u001b[1;32m    253\u001b[0m         (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gluon/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3519\u001b[0m     \"\"\"\n\u001b[1;32m   3520\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3521\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gluon/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3427\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3429\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3430\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gluon/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3574\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3575\u001b[0m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3576\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_median_nancheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3577\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3578\u001b[0m         \u001b[0;31m# if there are no nans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gluon/lib/python3.6/site-packages/numpy/lib/utils.py\u001b[0m in \u001b[0;36m_median_nancheck\u001b[0;34m(data, result, axis, out)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "\n",
    "mnist=tf.keras.datasets.fashion_mnist \n",
    "(training_images,training_labels),(test_images,test_labels)=mnist.load_data()\n",
    "print(training_images.shape)\n",
    "print(training_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "training_images=training_images.reshape(60000,28,28,1) \n",
    "training_images=training_images/255.0 \n",
    "test_images=test_images.reshape(10000,28,28,1) \n",
    "test_images=test_images/255.0 \n",
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dense(10,activation='softmax')     \n",
    "])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary() \n",
    "model.fit(training_images,training_labels,epochs=5) \n",
    "test_loss=model.evaluate(test_images,test_labels) \n",
    "print(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='tanh',input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='tanh'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation='tanh'),\n",
    "    tf.keras.layers.Dense(10,activation='softmax')     \n",
    "])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary() \n",
    "model.fit(training_images,training_labels,epochs=5) \n",
    "test_loss=model.evaluate(test_images,test_labels)\n",
    "print(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "\n",
    "mnist=tf.keras.datasets.fashion_mnist \n",
    "(training_images,training_labels),(test_images,test_labels)=mnist.load_data()\n",
    "print(training_images.shape)\n",
    "print(training_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "training_images=training_images.reshape(60000,28,28,1) \n",
    "training_images=training_images/255.0 \n",
    "test_images=test_images.reshape(10000,28,28,1) \n",
    "test_images=test_images/255.0 \n",
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='softmax',input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dense(10,activation='softmax')     \n",
    "])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary() \n",
    "model.fit(training_images,training_labels,epochs=5) \n",
    "test_loss=model.evaluate(test_images,test_labels) \n",
    "print(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.4335 - acc: 0.8436\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.2932 - acc: 0.8921\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.2502 - acc: 0.9079\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.2160 - acc: 0.9190\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.1881 - acc: 0.9304\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.1660 - acc: 0.9379\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.1456 - acc: 0.9455\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.1275 - acc: 0.9519\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.1105 - acc: 0.9585\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0979 - acc: 0.9639\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0866 - acc: 0.9675\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.0757 - acc: 0.9708\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0673 - acc: 0.9752\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0606 - acc: 0.9773\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0537 - acc: 0.9805\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.0491 - acc: 0.9820\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0461 - acc: 0.9826\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0387 - acc: 0.9857\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.0394 - acc: 0.9854\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0377 - acc: 0.9861\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0340 - acc: 0.9874\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0357 - acc: 0.9872\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0294 - acc: 0.9891\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.0306 - acc: 0.9893\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.0268 - acc: 0.9909\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0250 - acc: 0.9909\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0263 - acc: 0.9908\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0221 - acc: 0.9920\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.0268 - acc: 0.9906\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0219 - acc: 0.9920\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.0214 - acc: 0.9924\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.0269 - acc: 0.9907\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0180 - acc: 0.9939\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.0198 - acc: 0.9924\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0205 - acc: 0.9927\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0212 - acc: 0.9929\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0171 - acc: 0.9938\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0210 - acc: 0.9931\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0216 - acc: 0.9932\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0204 - acc: 0.9935\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0166 - acc: 0.9943\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0184 - acc: 0.9938\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0189 - acc: 0.9939\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0172 - acc: 0.9945\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 13s 225us/step - loss: 0.0203 - acc: 0.9935\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0138 - acc: 0.9958\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0214 - acc: 0.9934\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0183 - acc: 0.9942\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0177 - acc: 0.9949\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0173 - acc: 0.9945\n",
      "10000/10000 [==============================] - 1s 108us/step\n",
      "[0.7632082026432443, 0.9084]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "\n",
    "mnist=tf.keras.datasets.fashion_mnist \n",
    "(training_images,training_labels),(test_images,test_labels)=mnist.load_data()\n",
    "print(training_images.shape)\n",
    "print(training_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "training_images=training_images.reshape(60000,28,28,1) \n",
    "training_images=training_images/255.0 \n",
    "test_images=test_images.reshape(10000,28,28,1) \n",
    "test_images=test_images/255.0 \n",
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dense(10,activation='softmax')     \n",
    "])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# model.summary() \n",
    "model.fit(training_images,training_labels,epochs=50) \n",
    "test_loss=model.evaluate(test_images,test_labels) \n",
    "print(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "f,axarr=plt.subplots(3,4) \n",
    "FIRST_IMAGE=0\n",
    "SECOND_IMAGE=7\n",
    "THIRD_IMAGE=26\n",
    "CONVOLUTION_NUMBER=1 \n",
    "from tensorflow.keras import models \n",
    "layer_outputs=[layer.output for layer in model.layers] \n",
    "activation_model=tf.keras.models.Model(inputs=model.input,outputs=layer_outputs)\n",
    "for x in range(0,4):\n",
    "    f1=activation_model.predict(test_images[FIRST_IMAGE].reshape(1,28,28,1))[x]\n",
    "    axarr[0,x].imshow(f1[0,:,:,CONVOLUTION_NUMBER],cmap='inferno')\n",
    "    axarr[0,x].grid(False) \n",
    "    f2=activation_model.predict(test_images[SECOND_IMAGE].reshape(1,28,28,1))[x] \n",
    "    axarr[1,x].imshow(f2[0,:,:,CONVOLUTION_NUMBER],cmap='inferno')\n",
    "    axarr[1,x].grid(False) \n",
    "    f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[2,x].grid(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "f,axarr=plt.subplots(3,4) \n",
    "FIRST_IMAGE=1\n",
    "SECOND_IMAGE=1\n",
    "THIRD_IMAGE=1\n",
    "CONVOLUTION_NUMBER=1 \n",
    "from tensorflow.keras import models \n",
    "layer_outputs=[layer.output for layer in model.layers] \n",
    "activation_model=tf.keras.models.Model(inputs=model.input,outputs=layer_outputs)\n",
    "for x in range(0,4):\n",
    "    f1=activation_model.predict(test_images[FIRST_IMAGE].reshape(1,28,28,1))[x]\n",
    "    axarr[0,x].imshow(f1[0,:,:,CONVOLUTION_NUMBER],cmap='inferno')\n",
    "    axarr[0,x].grid(False) \n",
    "    f2=activation_model.predict(test_images[SECOND_IMAGE].reshape(1,28,28,1))[x] \n",
    "    axarr[1,x].imshow(f2[0,:,:,CONVOLUTION_NUMBER],cmap='inferno')\n",
    "    axarr[1,x].grid(False) \n",
    "    f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[2,x].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "f,axarr=plt.subplots(3,4) \n",
    "FIRST_IMAGE=4\n",
    "SECOND_IMAGE=7\n",
    "THIRD_IMAGE=5\n",
    "CONVOLUTION_NUMBER=4\n",
    "from tensorflow.keras import models \n",
    "layer_outputs=[layer.output for layer in model.layers] \n",
    "activation_model=tf.keras.models.Model(inputs=model.input,outputs=layer_outputs)\n",
    "for x in range(0,4):\n",
    "    f1=activation_model.predict(test_images[FIRST_IMAGE].reshape(1,28,28,1))[x]\n",
    "    axarr[0,x].imshow(f1[0,:,:,CONVOLUTION_NUMBER],cmap='inferno')\n",
    "    axarr[0,x].grid(False) \n",
    "    f2=activation_model.predict(test_images[SECOND_IMAGE].reshape(1,28,28,1))[x] \n",
    "    axarr[1,x].imshow(f2[0,:,:,CONVOLUTION_NUMBER],cmap='inferno')\n",
    "    axarr[1,x].grid(False) \n",
    "    f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[2,x].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
