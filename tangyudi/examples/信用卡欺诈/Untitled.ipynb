{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "count_classes = pd.value_counts(data['Class'], sort = True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pd.value_counts(data['Class'],sort=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fe98f9344e0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAETCAYAAADge6tNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe98f8d7978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time','Amount'],axis=1)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "         V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9       V10     ...           V20       V21       V22  \\\n",
      "0  0.098698  0.363787  0.090794     ...      0.251412 -0.018307  0.277838   \n",
      "1  0.085102 -0.255425 -0.166974     ...     -0.069083 -0.225775 -0.638672   \n",
      "2  0.247676 -1.514654  0.207643     ...      0.524980  0.247998  0.771679   \n",
      "3  0.377436 -1.387024 -0.054952     ...     -0.208038 -0.108300  0.005274   \n",
      "4 -0.270533  0.817739  0.753074     ...      0.408542 -0.009431  0.798278   \n",
      "\n",
      "        V23       V24       V25       V26       V27       V28  normAmount  \n",
      "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053    0.244964  \n",
      "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   -0.342475  \n",
      "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752    1.160686  \n",
      "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458    0.140534  \n",
      "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   -0.073403  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "   Class\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n"
     ]
    }
   ],
   "source": [
    "print('1'*100)\n",
    "X = data.loc[:, data.columns != 'Class']\n",
    "print(X[:5])\n",
    "y = data.loc[:, data.columns == 'Class']\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n",
      "[   541    623   4920   6108   6329   6331   6334   6336   6338   6427\n",
      "   6446   6472   6529   6609   6641   6717   6719   6734   6774   6820\n",
      "   6870   6882   6899   6903   6971   8296   8312   8335   8615   8617\n",
      "   8842   8845   8972   9035   9179   9252   9487   9509  10204  10484\n",
      "  10497  10498  10568  10630  10690  10801  10891  10897  11343  11710\n",
      "  11841  11880  12070  12108  12261  12369  14104  14170  14197  14211\n",
      "  14338  15166  15204  15225  15451  15476  15506  15539  15566  15736\n",
      "  15751  15781  15810  16415  16780  16863  17317  17366  17407  17453\n",
      "  17480  18466  18472  18773  18809  20198  23308  23422  26802  27362\n",
      "  27627  27738  27749  29687  30100  30314  30384  30398  30442  30473\n",
      "  30496  31002  33276  39183  40085  40525  41395  41569  41943  42007\n",
      "  42009  42473  42528  42549  42590  42609  42635  42674  42696  42700\n",
      "  42741  42756  42769  42784  42856  42887  42936  42945  42958  43061\n",
      "  43160  43204  43428  43624  43681  43773  44001  44091  44223  44270\n",
      "  44556  45203  45732  46909  46918  46998  47802  48094  50211  50537\n",
      "  52466  52521  52584  53591  53794  55401  56703  57248  57470  57615\n",
      "  58422  58761  59539  61787  63421  63634  64329  64411  64460  68067\n",
      "  68320  68522  68633  69498  69980  70141  70589  72757  73784  73857\n",
      "  74496  74507  74794  75511  76555  76609  76929  77099  77348  77387\n",
      "  77682  79525  79536  79835  79874  79883  80760  81186  81609  82400\n",
      "  83053  83297  83417  84543  86155  87354  88258  88307  88876  88897\n",
      "  89190  91671  92777  93424  93486  93788  94218  95534  95597  96341\n",
      "  96789  96994  99506 100623 101509 102441 102442 102443 102444 102445\n",
      " 102446 102782 105178 106679 106998 107067 107637 108258 108708 111690\n",
      " 112840 114271 116139 116404 118308 119714 119781 120505 120837 122479\n",
      " 123141 123201 123238 123270 123301 124036 124087 124115 124176 125342\n",
      " 128479 131272 135718 137705 140786 141257 141258 141259 141260 142405\n",
      " 142557 143188 143333 143334 143335 143336 143728 143731 144104 144108\n",
      " 144754 145800 146790 147548 147605 149145 149357 149522 149577 149587\n",
      " 149600 149869 149874 150601 150644 150647 150654 150660 150661 150662\n",
      " 150663 150665 150666 150667 150668 150669 150677 150678 150679 150680\n",
      " 150684 150687 150692 150697 150715 150925 151006 151007 151008 151009\n",
      " 151011 151103 151196 151462 151519 151730 151807 152019 152223 152295\n",
      " 153823 153835 153885 154234 154286 154371 154454 154587 154633 154668\n",
      " 154670 154676 154684 154693 154694 154697 154718 154719 154720 154960\n",
      " 156988 156990 157585 157868 157871 157918 163149 163586 167184 167305\n",
      " 172787 176049 177195 178208 181966 182992 183106 184379 189587 189701\n",
      " 189878 190368 191074 191267 191359 191544 191690 192382 192529 192584\n",
      " 192687 195383 197586 198868 199896 201098 201601 203324 203328 203700\n",
      " 204064 204079 204503 208651 212516 212644 213092 213116 214662 214775\n",
      " 215132 215953 215984 218442 219025 219892 220725 221018 221041 222133\n",
      " 222419 223366 223572 223578 223618 226814 226877 229712 229730 230076\n",
      " 230476 231978 233258 234574 234632 234633 234705 235616 235634 235644\n",
      " 237107 237426 238222 238366 238466 239499 239501 240222 241254 241445\n",
      " 243393 243547 243699 243749 243848 244004 244333 245347 245556 247673\n",
      " 247995 248296 248971 249167 249239 249607 249828 249963 250761 251477\n",
      " 251866 251881 251891 251904 252124 252774 254344 254395 255403 255556\n",
      " 258403 261056 261473 261925 262560 262826 263080 263274 263324 263877\n",
      " 268375 272521 274382 274475 275992 276071 276864 279863 280143 280149\n",
      " 281144 281674]\n"
     ]
    }
   ],
   "source": [
    "# Number of data points in the minority class\n",
    "number_records_fraud = len(data[data.Class == 1])\n",
    "print(number_records_fraud)\n",
    "fraud_indices = np.array(data[data.Class == 1].index)\n",
    "print(fraud_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of normal transactions:  0.5\n",
      "Percentage of fraud transactions:  0.5\n",
      "Total number of transactions in resampled data:  984\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Picking the indices of the normal classes\n",
    "normal_indices = data[data.Class == 0].index\n",
    "\n",
    "# Out of the indices we picked, randomly select \"x\" number (number_records_fraud)\n",
    "random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "# Appending the 2 indices\n",
    "under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n",
    "\n",
    "# Under sample dataset\n",
    "under_sample_data = data.iloc[under_sample_indices,:]\n",
    "\n",
    "X_undersample = under_sample_data.loc[:, under_sample_data.columns != 'Class']\n",
    "y_undersample = under_sample_data.loc[:, under_sample_data.columns == 'Class']\n",
    "\n",
    "# Showing ratio\n",
    "print(\"Percentage of normal transactions: \", len(under_sample_data[under_sample_data.Class == 0])/len(under_sample_data))\n",
    "print(\"Percentage of fraud transactions: \", len(under_sample_data[under_sample_data.Class == 1])/len(under_sample_data))\n",
    "print(\"Total number of transactions in resampled data: \", len(under_sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions train dataset:  199364\n",
      "Number transactions test dataset:  85443\n",
      "Total number of transactions:  284807\n",
      "\n",
      "Number transactions train dataset:  688\n",
      "Number transactions test dataset:  296\n",
      "Total number of transactions:  984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Whole dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "print(\"Number transactions train dataset: \", len(X_train))\n",
    "print(\"Number transactions test dataset: \", len(X_test))\n",
    "print(\"Total number of transactions: \", len(X_train)+len(X_test))\n",
    "\n",
    "# Undersampled dataset\n",
    "X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample\n",
    "                                                                                                   ,y_undersample\n",
    "                                                                                                   ,test_size = 0.3\n",
    "                                                                                                   ,random_state = 0)\n",
    "print(\"\")\n",
    "print(\"Number transactions train dataset: \", len(X_train_undersample))\n",
    "print(\"Number transactions test dataset: \", len(X_test_undersample))\n",
    "print(\"Total number of transactions: \", len(X_train_undersample)+len(X_test_undersample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Recall = TP/(TP+FN)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,recall_score,classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def printing_Kfold_scores(x_train_data,y_train_data):\n",
    "    fold = KFold(5,shuffle=False) \n",
    "    type(fold)\n",
    "    # Different C parameters\n",
    "    c_param_range = [0.01,0.1,1,10,100]\n",
    "\n",
    "    results_table = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Mean recall score'])\n",
    "    results_table['C_parameter'] = c_param_range\n",
    "\n",
    "    # the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n",
    "    j = 0\n",
    "    for c_param in c_param_range:\n",
    "        print('-------------------------------------------')\n",
    "        print('C parameter: ', c_param)\n",
    "        print('-------------------------------------------')\n",
    "        print('')\n",
    "\n",
    "        recall_accs = []\n",
    "        for iteration, indices in enumerate(fold,start=1):\n",
    "\n",
    "            # Call the logistic regression model with a certain C parameter\n",
    "            lr = LogisticRegression(C = c_param, penalty = 'l1')\n",
    "\n",
    "            # Use the training data to fit the model. In this case, we use the portion of the fold to train the model\n",
    "            # with indices[0]. We then predict on the portion assigned as the 'test cross validation' with indices[1]\n",
    "            lr.fit(x_train_data.iloc[indices[0],:],y_train_data.iloc[indices[0],:].values.ravel())\n",
    "\n",
    "            # Predict values using the test indices in the training data\n",
    "            y_pred_undersample = lr.predict(x_train_data.iloc[indices[1],:].values)\n",
    "\n",
    "            # Calculate the recall score and append it to a list for recall scores representing the current c_parameter\n",
    "            recall_acc = recall_score(y_train_data.iloc[indices[1],:].values,y_pred_undersample)\n",
    "            recall_accs.append(recall_acc)\n",
    "            print('Iteration ', iteration,': recall score = ', recall_acc)\n",
    "\n",
    "        # The mean value of those recall scores is the metric we want to save and get hold of.\n",
    "        results_table.ix[j,'Mean recall score'] = np.mean(recall_accs)\n",
    "        j += 1\n",
    "        print('')\n",
    "        print('Mean recall score ', np.mean(recall_accs))\n",
    "        print('')\n",
    "\n",
    "    best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter']\n",
    "    \n",
    "    # Finally, we can check which C parameter is the best amongst the chosen.\n",
    "    print('*********************************************************************************')\n",
    "    print('Best model to choose from cross validation is with C parameter = ', best_c)\n",
    "    print('*********************************************************************************')\n",
    "    \n",
    "    return best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "C parameter:  0.01\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'KFold' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9cd134e2d0f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprinting_Kfold_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_undersample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_undersample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-932ca1239a28>\u001b[0m in \u001b[0;36mprinting_Kfold_scores\u001b[0;34m(x_train_data, y_train_data)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mrecall_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Call the logistic regression model with a certain C parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'KFold' object is not iterable"
     ]
    }
   ],
   "source": [
    "best_c = printing_Kfold_scores(X_train_undersample,y_train_undersample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "lr = LogisticRegression(C = best_c, penalty = 'l1')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred_undersample = lr.predict(X_test_undersample.values)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test_undersample,y_pred_undersample)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = best_c, penalty = 'l1')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred = lr.predict(X_test.values)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = printing_Kfold_scores(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = best_c, penalty = 'l1')\n",
    "lr.fit(X_train,y_train.values.ravel())\n",
    "y_pred_undersample = lr.predict(X_test.values)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred_undersample)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = 0.01, penalty = 'l1')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred_undersample_proba = lr.predict_proba(X_test_undersample.values)\n",
    "\n",
    "thresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "j = 1\n",
    "for i in thresholds:\n",
    "    y_test_predictions_high_recall = y_pred_undersample_proba[:,1] > i\n",
    "    \n",
    "    plt.subplot(3,3,j)\n",
    "    j += 1\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test_undersample,y_test_predictions_high_recall)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    class_names = [0,1]\n",
    "    plot_confusion_matrix(cnf_matrix\n",
    "                          , classes=class_names\n",
    "                          , title='Threshold >= %s'%i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_cards=pd.read_csv('creditcard.csv')\n",
    "\n",
    "columns=credit_cards.columns\n",
    "# The labels are in the last column ('Class'). Simply remove it to obtain features columns\n",
    "features_columns=columns.delete(len(columns)-1)\n",
    "\n",
    "features=credit_cards[features_columns]\n",
    "labels=credit_cards['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, \n",
    "                                                                            labels, \n",
    "                                                                            test_size=0.2, \n",
    "                                                                            random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SMOTE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-89645b0e07c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moversampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moversampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SMOTE' is not defined"
     ]
    }
   ],
   "source": [
    "oversampler=SMOTE(random_state=0)\n",
    "os_features,os_labels=oversampler.fit_sample(features_train,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os_labels[os_labels==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_features = pd.DataFrame(os_features)\n",
    "os_labels = pd.DataFrame(os_labels)\n",
    "best_c = printing_Kfold_scores(os_features,os_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = best_c, penalty = 'l1')\n",
    "lr.fit(os_features,os_labels.values.ravel())\n",
    "y_pred = lr.predict(features_test.values)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(labels_test,y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
