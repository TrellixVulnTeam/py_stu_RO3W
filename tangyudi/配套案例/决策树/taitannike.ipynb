{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas #ipython notebook\n",
    "titanic = pandas.read_csv(\"titanic_train.csv\")\n",
    "titanic.head(5)\n",
    "#print (titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  891.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.361582    0.523008   \nstd     257.353842    0.486592    0.836071   13.019697    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   35.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "print (titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['male' 'female']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print (titanic[\"Sex\"].unique())\n",
    "\n",
    "# Replace all the occurences of male with the number 0.\n",
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['S' 'C' 'Q' nan]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print (titanic[\"Embarked\"].unique())\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('S')\n",
    "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "d:\\ai\\workspace\\py_stu\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n  FutureWarning\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Import the linear regression class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Sklearn also has a helper that makes it easy to do cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# The columns we'll use to predict the target\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm class\n",
    "alg = LinearRegression()\n",
    "# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n",
    "# We set random_state to ensure we get the same splits every time we run this.\n",
    "kf = KFold(titanic.shape[0],n_splits=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for i,(train, test) in enumerate(kf.split(titanic)):\n",
    "    # print('train:')\n",
    "    # print(train)\n",
    "    # print('test:')\n",
    "    # print(test)\n",
    "    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n",
    "    train_predictors = (titanic[predictors].iloc[train,:])\n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    # Training the algorithm using the predictors and target.\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    # We can now make predictions on the test fold\n",
    "    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n",
    "    predictions.append(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.2671156004489338\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n",
    "# We concatenate them on axis 0, as they only have one axis.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.7957351290684623\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "d:\\ai\\workspace\\py_stu\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\nd:\\ai\\workspace\\py_stu\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\nd:\\ai\\workspace\\py_stu\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# from sklearn import cross_validation\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialize our algorithm\n",
    "alg = LogisticRegression(random_state=1)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "scores = model_selection.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "titanic_test = pandas.read_csv(\"test.csv\")\n",
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic_test[\"Fare\"] = titanic_test[\"Fare\"].fillna(titanic_test[\"Fare\"].median())\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0 \n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "titanic_test[\"Embarked\"] = titanic_test[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "d:\\ai\\workspace\\py_stu\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n  FutureWarning\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "0.8069584736251403\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm with the default paramters\n",
    "# n_estimators is the number of trees we want to make\n",
    "# min_samples_split is the minimum number of rows we need to make a split\n",
    "# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "# kf = KFold(titanic.shape[0],n_splits=3, random_state=1)\n",
    "kf = model_selection.KFold(titanic.shape[0], n_splits=3, random_state=1)\n",
    "scores = model_selection.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
    "\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "d:\\ai\\workspace\\py_stu\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n  FutureWarning\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "0.8260381593714927\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=4, min_samples_leaf=2)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "kf = model_selection.KFold(titanic.shape[0], n_splits=3, random_state=1)\n",
    "scores = model_selection.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
    "\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Generating a familysize column\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "\n",
    "\n",
    "# The .apply method generates a new series\n",
    "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Mr          517\nMiss        182\nMrs         125\nMaster       40\nDr            7\nRev           6\nMajor         2\nCol           2\nMlle          2\nMs            1\nMme           1\nSir           1\nLady          1\nDon           1\nJonkheer      1\nCountess      1\nCapt          1\nName: Name, dtype: int64\n1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n0      1\n1      3\n2      2\n3      3\n4      1\n      ..\n886    6\n887    2\n888    2\n889    1\n890    1\nName: Name, Length: 891, dtype: object\n2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n1     517\n2     183\n3     125\n4      40\n5       7\n6       6\n7       5\n10      3\n8       3\n9       2\nName: Name, dtype: int64\n3333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333\n0      1\n1      3\n2      2\n3      3\n4      1\n      ..\n886    6\n887    2\n888    2\n889    1\n890    1\nName: Name, Length: 891, dtype: object\n4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# A function to get the title from a name.\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Get all the titles and print how often each one occurs.\n",
    "titles = titanic[\"Name\"].apply(get_title)\n",
    "print(pandas.value_counts(titles))\n",
    "\n",
    "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "\n",
    "# Verify that we converted everything.\n",
    "print('1'*100)\n",
    "print(titles)\n",
    "print('2'*100)\n",
    "print(pandas.value_counts(titles))\n",
    "print('3'*100)\n",
    "print(titles)\n",
    "print('4'*100)\n",
    "# Add in the title column.\n",
    "titanic[\"Title\"] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 验证那些特征比较重要 \n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\",'FamilySize','Title','NameLength']\n",
    "#Perform feature selection\n",
    "selector=SelectKBest(f_classif,k=5)\n",
    "selector.fit(titanic[predictors],titanic['Survived'])\n",
    "scores=-np.log10(selector.pvalues_)\n",
    "plt.bar(range(len(predictors)),scores)\n",
    "plt.xticks(range(len(predictors)),predictors,rotation='vertical')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "d:\\ai\\workspace\\py_stu\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n  FutureWarning\nd:\\ai\\workspace\\py_stu\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8352df90cb1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mtest_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mtest_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;31m# 计算出平局的结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Put all the predictions together into one array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ],
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "algorithms=[\n",
    "    [GradientBoostingClassifier(random_state=1,n_estimators=25,max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\",'FamilySize','Title','NameLength']],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]]\n",
    "]\n",
    "kf=KFold(titanic.shape[0],n_splits=3,random_state=1)\n",
    "predictors=[]\n",
    "for i,(train,test) in enumerate(kf.split(titanic)):\n",
    "    train_target=titanic['Survived'].iloc[train]\n",
    "    full_test_predictions=[]\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg,predictors in algorithms:\n",
    "        #Fix the algorithm on the training data \n",
    "        alg.fit(titanic[predictors].iloc[train,:],train_target)\n",
    "        # Select and predict on the test fold \n",
    "        # The astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error \n",
    "        test_predictions=alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    test_predictions=(full_test_predictions[0]+full_test_predictions[1])/2\n",
    "    test_predictions[test_predictions<=0.5]=0\n",
    "    test_predictions[test_predictions>0.5]=1\n",
    "    predictions.append(test_predictions)\n",
    "# 计算出平局的结果 \n",
    "# Put all the predictions together into one array\n",
    "predictions=np.concatenate(predictions,axis=0)\n",
    "accuracy=sum(predictions[predictions==titanic['Survived']])/len(predictions)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}